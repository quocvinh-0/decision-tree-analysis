import matplotlib
matplotlib.use('Agg')  # Sá»­ dá»¥ng backend non-interactive Ä‘á»ƒ trÃ¡nh lá»—i tkinter
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import os
from sklearn.tree import plot_tree
from sklearn.model_selection import learning_curve
from scipy import stats

def create_all_visualizations(train_df, test_df, feature_importance_df, best_model_info, 
                            comparison_results, X_scaled, y):
    """Táº¡o táº¥t cáº£ cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan"""
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    
    # 1. Biá»ƒu Ä‘á»“ so sÃ¡nh mÃ´ hÃ¬nh
    create_model_comparison_chart(comparison_results)
    
    # 2. Biá»ƒu Ä‘á»“ feature importance
    create_feature_importance_chart(feature_importance_df)
    
    # 3. Biá»ƒu Ä‘á»“ Actual vs Predicted
    create_actual_vs_predicted_chart(best_model_info, comparison_results)
    
    # 4. Biá»ƒu Ä‘á»“ tá»•ng há»£p 10 láº§n cháº¡y
    create_summary_plots(train_df, test_df, comparison_results)
    
    # 5. PhÃ¢n tÃ­ch sai sá»‘
    create_residuals_analysis(best_model_info, comparison_results)
    
    # 6. Learning curves
    create_learning_curves(best_model_info, comparison_results, X_scaled, y)
    
    # 7. Biá»ƒu Ä‘á»“ so sÃ¡nh chi tiáº¿t 10 láº§n láº·p
    create_detailed_comparison_plots(train_df, test_df, best_model_info)
    
    # 8. Biá»ƒu Ä‘á»“ chi tiáº¿t tá»«ng láº§n cháº¡y
    create_detailed_runs_analysis(train_df, test_df, best_model_info)
    
    # 9. Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh
    plot_decision_tree(best_model_info)

def create_model_comparison_chart(comparison_results):
    """Biá»ƒu Ä‘á»“ so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh"""
    print("\nğŸ“Š 1. Biá»ƒu Ä‘á»“ so sÃ¡nh mÃ´ hÃ¬nh")
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    comparison_path = os.path.join('img', 'model_comparison.png')
    
    plt.figure(figsize=(10, 6))
    models = ['Decision Tree', 'Random Forest']  # Bá» KNN
    r2_scores = [
        comparison_results['decision_tree']['metrics']['r2'],
        comparison_results['random_forest']['metrics']['r2']
    ]
    colors = ['#2ECC71', '#3498DB']  # Bá» KNN
    
    # ThÃªm Naive Bayes náº¿u cÃ³
    if 'naive_bayes' in comparison_results:
        models.append('Naive Bayes')
        r2_scores.append(comparison_results['naive_bayes']['metrics']['r2'])
        colors.append('#E74C3C')
    
    bars = plt.bar(models, r2_scores, color=colors, alpha=0.8, edgecolor='black')
    plt.ylabel('RÂ² Score', fontsize=12)
    plt.title('SO SÃNH HIá»†U SUáº¤T CÃC MÃ” HÃŒNH', fontweight='bold', fontsize=14)
    plt.ylim(0.8, 1.0)
    plt.grid(True, alpha=0.3)
    
    for bar, score in zip(bars, r2_scores):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
                 f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
    
    plt.tight_layout()
    plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {comparison_path}")

def create_feature_importance_chart(feature_importance_df):
    """Biá»ƒu Ä‘á»“ feature importance"""
    print("ğŸ“Š 2. Biá»ƒu Ä‘á»“ feature importance")
    feature_img_path = os.path.join('img', 'feature_importance.png')
    
    plt.figure(figsize=(10, 6))
    features = feature_importance_df['Äáº·c trÆ°ng']
    importances = feature_importance_df['Äá»™ quan trá»ng trung bÃ¬nh']
    std_dev = feature_importance_df['Äá»™ lá»‡ch chuáº©n']
    
    bars = plt.bar(features, importances, yerr=std_dev, capsize=8, 
                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'], 
                   alpha=0.8, edgecolor='black')
    plt.ylabel('Äá»™ quan trá»ng trung bÃ¬nh', fontsize=12)
    plt.title('Äá»˜ QUAN TRá»ŒNG Äáº¶C TRÆ¯NG (10 Láº¦N CHáº Y)', fontweight='bold', fontsize=14)
    plt.xticks(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    for bar, importance, std in zip(bars, importances, std_dev):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                 f'{importance:.3f} (Â±{std:.3f})', ha='center', va='bottom', 
                 fontweight='bold', fontsize=10)
    
    plt.tight_layout()
    plt.savefig(feature_img_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {feature_img_path}")

def create_actual_vs_predicted_chart(best_model_info, comparison_results):
    """Biá»ƒu Ä‘á»“ so sÃ¡nh giÃ¡ trá»‹ thá»±c vÃ  dá»± Ä‘oÃ¡n"""
    print("ğŸ“Š 3. Biá»ƒu Ä‘á»“ Actual vs Predicted")
    actual_pred_path = os.path.join('img', 'actual_vs_predicted.png')
    
    plt.figure(figsize=(12, 5))  # Giáº£m width vÃ¬ chá»‰ cÃ²n 2 subplot
    y_test = best_model_info['y_test']
    
    # Decision Tree
    plt.subplot(1, 2, 1)  # Äá»•i tá»« 1,3,1 thÃ nh 1,2,1 (bá» KNN)
    y_pred_dt = best_model_info['y_pred_test']
    dt_r2 = comparison_results['decision_tree']['metrics']['r2']
    plt.scatter(y_test, y_pred_dt, alpha=0.6, s=30, color='blue')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
    plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
    plt.title(f'Decision Tree\nRÂ² = {dt_r2:.3f}')
    plt.grid(True, alpha=0.3)
    
    # Random Forest
    plt.subplot(1, 2, 2)  # Äá»•i tá»« 1,3,2 thÃ nh 1,2,2 (bá» KNN)
    y_pred_rf = comparison_results['random_forest']['predictions']
    rf_r2 = comparison_results['random_forest']['metrics']['r2']
    plt.scatter(y_test, y_pred_rf, alpha=0.6, s=30, color='green')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
    plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
    plt.title(f'Random Forest\nRÂ² = {rf_r2:.3f}')
    plt.grid(True, alpha=0.3)
    
    # Bá» KNN
    # # KNN
    # plt.subplot(1, 3, 3)
    # y_pred_knn = comparison_results['knn']['predictions']
    # knn_r2 = comparison_results['knn']['metrics']['r2']
    # plt.scatter(y_test, y_pred_knn, alpha=0.6, s=30, color='purple')
    # plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    # plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
    # plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
    # plt.title(f'KNN\nRÂ² = {knn_r2:.3f}')
    # plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(actual_pred_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {actual_pred_path}")

def create_summary_plots(train_df, test_df, comparison_results):
    """Biá»ƒu Ä‘á»“ tá»•ng há»£p káº¿t quáº£"""
    print("ğŸ“Š 4. Biá»ƒu Ä‘á»“ tá»•ng há»£p 10 láº§n cháº¡y")
    summary_plots_path = os.path.join('img', 'summary_plots.png')
    
    plt.figure(figsize=(20, 12))
    plt.suptitle("PHÃ‚N TÃCH Tá»”NG Há»¢P 10 Láº¦N HUáº¤N LUYá»†N DECISION TREE", 
                 fontsize=20, fontweight='bold', y=1.03)
    
    # Biá»ƒu Ä‘á»“ 1: So sÃ¡nh RÂ² qua 10 láº§n cháº¡y
    plt.subplot(2, 3, 1)
    runs = range(1, 11)
    plt.plot(runs, train_df['r2'], marker='o', linewidth=2, markersize=8, 
             label='Train RÂ²', color='#2ECC71')
    plt.plot(runs, test_df['r2'], marker='s', linewidth=2, markersize=8, 
             label='Test RÂ²', color='#E74C3C')
    plt.axhline(y=test_df['r2'].mean(), color='red', linestyle='--', alpha=0.7, 
                label=f"Test RÂ² TB: {test_df['r2'].mean():.3f}")
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('RÂ² Score')
    plt.title('SO SÃNH RÂ² QUA 10 Láº¦N CHáº Y', fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 2: So sÃ¡nh RMSE qua 10 láº§n cháº¡y
    plt.subplot(2, 3, 2)
    plt.plot(runs, train_df['rmse'], marker='o', linewidth=2, markersize=8, 
             label='Train RMSE', color='#3498DB')
    plt.plot(runs, test_df['rmse'], marker='s', linewidth=2, markersize=8, 
             label='Test RMSE', color='#F39C12')
    plt.axhline(y=test_df['rmse'].mean(), color='orange', linestyle='--', alpha=0.7, 
                label=f"Test RMSE TB: {test_df['rmse'].mean():.3f}")
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('RMSE')
    plt.title('SO SÃNH RMSE QUA 10 Láº¦N CHáº Y', fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 3: PhÃ¢n bá»‘ RÂ² trÃªn táº­p test
    plt.subplot(2, 3, 3)
    sns.boxplot(data=[train_df['r2'], test_df['r2']], palette=['#AED6F1', '#FAD7A0'])
    plt.xticks([0, 1], ['Train RÂ²', 'Test RÂ²'])
    plt.ylabel('RÂ² Score')
    plt.title('PHÃ‚N Bá» RÂ² SCORE (10 Láº¦N)', fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 4: Hiá»‡u suáº¥t theo bá»™ tham sá»‘
    plt.subplot(2, 3, 4)
    param_names = [f"Set {i+1}" for i in range(10)]
    test_r2_values = test_df['r2']
    plt.scatter(param_names, test_r2_values, s=100, alpha=0.7, 
                c=test_r2_values, cmap='viridis')
    plt.axhline(y=test_r2_values.mean(), color='red', linestyle='--', label='Trung bÃ¬nh')
    plt.xlabel('Bá»™ tham sá»‘')
    plt.ylabel('Test RÂ²')
    plt.title('HIá»†U SUáº¤T THEO Bá»˜ THAM Sá»', fontweight='bold')
    plt.xticks(rotation=45, ha='right')
    plt.colorbar(label='RÂ² Score')
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 5: So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh (bá» KNN)
    plt.subplot(2, 3, 5)
    models_compare = ['DT', 'RF']  # Bá» KNN
    r2_compare = [
        comparison_results['decision_tree']['metrics']['r2'],
        comparison_results['random_forest']['metrics']['r2']
    ]
    colors_compare = ['#2ECC71', '#3498DB']  # Bá» KNN
    
    # ThÃªm Naive Bayes náº¿u cÃ³
    if 'naive_bayes' in comparison_results:
        models_compare.append('NB')
        r2_compare.append(comparison_results['naive_bayes']['metrics']['r2'])
        colors_compare.append('#E74C3C')
    
    plt.bar(models_compare, r2_compare, color=colors_compare)
    plt.ylabel('RÂ² Score')
    plt.title('SO SÃNH 3 MÃ” HÃŒNH', fontweight='bold')
    for i, v in enumerate(r2_compare):
        plt.text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 6: Cross-validation results
    plt.subplot(2, 3, 6)
    cv_folds = range(1, 6)
    cv_test_r2 = comparison_results['cv_results']['test_r2']
    plt.plot(cv_folds, cv_test_r2, marker='o', linewidth=2, markersize=8, color='#E74C3C')
    plt.axhline(y=cv_test_r2.mean(), color='red', linestyle='--', 
                label=f'Trung bÃ¬nh: {cv_test_r2.mean():.3f}')
    plt.xlabel('Fold')
    plt.ylabel('Test RÂ²')
    plt.title('CROSS-VALIDATION (5-fold)', fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(summary_plots_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {summary_plots_path}")
def create_residuals_analysis(best_model_info, comparison_results):
    """PhÃ¢n tÃ­ch sai sá»‘ (residuals analysis)"""
    print("ğŸ“Š 5. PhÃ¢n tÃ­ch sai sá»‘")
    
    y_test = best_model_info['y_test']
    residuals_dt = y_test - best_model_info['y_pred_test']
    residuals_rf = y_test - comparison_results['random_forest']['predictions']
    # Bá» KNN
    # residuals_knn = y_test - comparison_results['knn']['predictions']
    
    residuals_path = os.path.join('img', 'residuals_analysis.png')
    plt.figure(figsize=(18, 12))
    
    # Biá»ƒu Ä‘á»“ 1: Residuals vs Predicted cho DT
    plt.subplot(2, 3, 1)
    plt.scatter(best_model_info['y_pred_test'], residuals_dt, alpha=0.6, s=30, color='blue')
    plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
    plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
    plt.ylabel('Sai sá»‘ (Residuals)')
    plt.title(f'Decision Tree\nStd: {residuals_dt.std():.3f}')
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 2: Residuals vs Predicted cho RF
    plt.subplot(2, 3, 2)
    y_pred_rf = comparison_results['random_forest']['predictions']
    plt.scatter(y_pred_rf, residuals_rf, alpha=0.6, s=30, color='green')
    plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
    plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
    plt.ylabel('Sai sá»‘ (Residuals)')
    plt.title(f'Random Forest\nStd: {residuals_rf.std():.3f}')
    plt.grid(True, alpha=0.3)
    
    # Bá» KNN - Biá»ƒu Ä‘á»“ 3
    # # Biá»ƒu Ä‘á»“ 3: Residuals vs Predicted cho KNN
    # plt.subplot(2, 3, 3)
    # y_pred_knn = comparison_results['knn']['predictions']
    # plt.scatter(y_pred_knn, residuals_knn, alpha=0.6, s=30, color='purple')
    # plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
    # plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
    # plt.ylabel('Sai sá»‘ (Residuals)')
    # plt.title(f'KNN\nStd: {residuals_knn.std():.3f}')
    # plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 3: PhÃ¢n phá»‘i residuals (Ä‘á»•i tá»« 4 thÃ nh 3)
    plt.subplot(2, 3, 3)
    plt.hist(residuals_dt, bins=30, alpha=0.7, label=f'DT (std: {residuals_dt.std():.3f})', color='blue')
    plt.hist(residuals_rf, bins=30, alpha=0.7, label=f'RF (std: {residuals_rf.std():.3f})', color='green')
    # Bá» KNN
    # plt.hist(residuals_knn, bins=30, alpha=0.7, label=f'KNN (std: {residuals_knn.std():.3f})', color='purple')
    plt.xlabel('Sai sá»‘ (Residuals)')
    plt.ylabel('Táº§n suáº¥t')
    plt.title('PHÃ‚N PHá»I SAI Sá» Cá»¦A CÃC MÃ” HÃŒNH')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 5: Q-Q plot cho Decision Tree
    plt.subplot(2, 3, 5)
    stats.probplot(residuals_dt, dist="norm", plot=plt)
    plt.title('Q-Q Plot: Decision Tree Residuals')
    
    # Biá»ƒu Ä‘á»“ 6: So sÃ¡nh Ä‘á»™ lá»›n sai sá»‘ (bá» KNN)
    plt.subplot(2, 3, 6)
    residuals_abs = [np.abs(residuals_dt).mean(), np.abs(residuals_rf).mean()]  # Bá» KNN
    models_resid = ['Decision Tree', 'Random Forest']  # Bá» KNN
    bars = plt.bar(models_resid, residuals_abs, color=['blue', 'green'], alpha=0.7)  # Bá» KNN
    plt.ylabel('Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh (MAE)')
    plt.title('SO SÃNH Äá»˜ Lá»šN SAI Sá»')
    for bar, value in zip(bars, residuals_abs):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{value:.3f}', 
                 ha='center', va='bottom', fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(residuals_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {residuals_path}")
    
    # PhÃ¢n tÃ­ch thá»‘ng kÃª residuals (bá» KNN)
    print(f"\nğŸ“Š PHÃ‚N TÃCH THá»NG KÃŠ SAI Sá»:")
    print(f"    Decision Tree: Mean = {residuals_dt.mean():.4f}, Std = {residuals_dt.std():.4f}")
    print(f"    Random Forest: Mean = {residuals_rf.mean():.4f}, Std = {residuals_rf.std():.4f}")
    # Bá» KNN
    # print(f"    KNN:           Mean = {residuals_knn.mean():.4f}, Std = {residuals_knn.std():.4f}")

def create_learning_curves(best_model_info, comparison_results, X_scaled, y):
    """Táº¡o learning curves"""
    print("ğŸ“Š 6. Learning Curves")
    
    print("Äang váº½ vÃ  lÆ°u learning curves...")
    plot_and_save_learning_curve(best_model_info['model'], "Decision Tree (Best Model)", 
                                "learning_curve_dt.png", X_scaled, y)
    
    if 'model' in comparison_results['random_forest']:
        plot_and_save_learning_curve(comparison_results['random_forest']['model'], 
                                    "Random Forest", "learning_curve_rf.png", X_scaled, y)

def plot_and_save_learning_curve(estimator, title, filename, X, y, cv=5):
    """Váº½ vÃ  lÆ°u learning curve"""
    plt.figure(figsize=(10, 6))
    
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='r2', n_jobs=-1, random_state=42
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)
    
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_mean, 'o-', color="r", label="Training score", linewidth=2)
    plt.plot(train_sizes, test_mean, 'o-', color="g", label="Cross-validation score", linewidth=2)
    
    plt.xlabel("Sá»‘ lÆ°á»£ng máº«u training", fontsize=12)
    plt.ylabel("RÂ² Score", fontsize=12)
    plt.title(f"Learning Curve: {title}", fontweight='bold')
    plt.legend(loc="best")
    plt.grid(True, alpha=0.3)
    
    filepath = os.path.join('img', filename)
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   âœ… ÄÃ£ lÆ°u: {filepath}")

def create_detailed_comparison_plots(train_df, test_df, best_model_info):
    """Biá»ƒu Ä‘á»“ so sÃ¡nh chi tiáº¿t 10 láº§n láº·p"""
    print("ğŸ“Š 7. Biá»ƒu Ä‘á»“ so sÃ¡nh chi tiáº¿t 10 láº§n láº·p")
    
    comparison_10_runs_path = os.path.join('img', 'comparison_10_runs.png')
    plt.figure(figsize=(18, 12))
    
    # Biá»ƒu Ä‘á»“ 1: So sÃ¡nh RÂ² train vs test qua 10 láº§n
    plt.subplot(2, 3, 1)
    runs = range(1, 11)
    plt.plot(runs, train_df['r2'], marker='o', linewidth=3, markersize=8, 
             label=f'Train RÂ² (TB: {train_df["r2"].mean():.3f})', color='#2ECC71')
    plt.plot(runs, test_df['r2'], marker='s', linewidth=3, markersize=8, 
             label=f'Test RÂ² (TB: {test_df["r2"].mean():.3f})', color='#E74C3C')
    plt.axhline(y=train_df['r2'].mean(), color='#2ECC71', linestyle='--', alpha=0.5)
    plt.axhline(y=test_df['r2'].mean(), color='#E74C3C', linestyle='--', alpha=0.5)
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('RÂ² Score')
    plt.title('SO SÃNH RÂ² TRAIN vs TEST QUA 10 Láº¦N', fontweight='bold', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0.8, 1.0)
    
    # ThÃªm annotation cho láº§n cháº¡y tá»‘t nháº¥t
    best_run = best_model_info['run_id'] + 1
    best_test_r2 = best_model_info['test_r2']
    plt.annotate(f'Tá»‘t nháº¥t\nLáº§n {best_run}\nRÂ² = {best_test_r2:.3f}', 
                 xy=(best_run, best_test_r2), 
                 xytext=(best_run+0.5, best_test_r2-0.02),
                 arrowprops=dict(arrowstyle='->', color='red', lw=2),
                 fontweight='bold', color='red')
    
    # Biá»ƒu Ä‘á»“ 2: So sÃ¡nh RMSE train vs test qua 10 láº§n
    plt.subplot(2, 3, 2)
    plt.plot(runs, train_df['rmse'], marker='o', linewidth=3, markersize=8, 
             label=f'Train RMSE (TB: {train_df["rmse"].mean():.3f})', color='#3498DB')
    plt.plot(runs, test_df['rmse'], marker='s', linewidth=3, markersize=8, 
             label=f'Test RMSE (TB: {test_df["rmse"].mean():.3f})', color='#F39C12')
    plt.axhline(y=train_df['rmse'].mean(), color='#3498DB', linestyle='--', alpha=0.5)
    plt.axhline(y=test_df['rmse'].mean(), color='#F39C12', linestyle='--', alpha=0.5)
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('RMSE')
    plt.title('SO SÃNH RMSE TRAIN vs TEST QUA 10 Láº¦N', fontweight='bold', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 3: So sÃ¡nh MAE train vs test qua 10 láº§n
    plt.subplot(2, 3, 3)
    plt.plot(runs, train_df['mae'], marker='o', linewidth=3, markersize=8, 
             label=f'Train MAE (TB: {train_df["mae"].mean():.3f})', color='#9B59B6')
    plt.plot(runs, test_df['mae'], marker='s', linewidth=3, markersize=8, 
             label=f'Test MAE (TB: {test_df["mae"].mean():.3f})', color='#E67E22')
    plt.axhline(y=train_df['mae'].mean(), color='#9B59B6', linestyle='--', alpha=0.5)
    plt.axhline(y=test_df['mae'].mean(), color='#E67E22', linestyle='--', alpha=0.5)
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('MAE')
    plt.title('SO SÃNH MAE TRAIN vs TEST QUA 10 Láº¦N', fontweight='bold', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 4: PhÃ¢n bá»‘ chÃªnh lá»‡ch RÂ² (Overfitting)
    plt.subplot(2, 3, 4)
    r2_diff = train_df['r2'] - test_df['r2']
    plt.bar(runs, r2_diff, color=np.where(r2_diff > 0.1, '#E74C3C', '#2ECC71'), alpha=0.7)
    plt.axhline(y=r2_diff.mean(), color='red', linestyle='--', 
               label=f'Trung bÃ¬nh: {r2_diff.mean():.3f}')
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('ChÃªnh lá»‡ch RÂ² (Train - Test)')
    plt.title('ÄÃNH GIÃ OVERFITTING QUA 10 Láº¦N', fontweight='bold', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ThÃªm giÃ¡ trá»‹ trÃªn cÃ¡c cá»™t
    for i, v in enumerate(r2_diff):
        plt.text(i+1, v + 0.001, f'{v:.3f}', ha='center', va='bottom', 
                 fontsize=9, fontweight='bold', 
                 color='red' if v > 0.1 else 'green')
    
    # Biá»ƒu Ä‘á»“ 5: Hiá»‡u suáº¥t theo bá»™ tham sá»‘ (Heatmap style)
    plt.subplot(2, 3, 5)
    # Táº¡o dá»¯ liá»‡u cho heatmap
    param_names = [f"Láº§n {i+1}" for i in range(10)]
    metrics = ['RÂ²', 'RMSE', 'MAE']
    performance_data = np.array([
        test_df['r2'].values,
        test_df['rmse'].values,
        test_df['mae'].values
    ])
    
    im = plt.imshow(performance_data, cmap='RdYlGn', aspect='auto')
    plt.xticks(range(10), param_names, rotation=45)
    plt.yticks(range(3), metrics)
    plt.title('MA TRáº¬N HIá»†U SUáº¤T 10 Láº¦N CHáº Y', fontweight='bold', fontsize=14)
    
    # ThÃªm giÃ¡ trá»‹ vÃ o Ã´ - RÂ² hiá»ƒn thá»‹ 3 chá»¯ sá»‘ tháº­p phÃ¢n
    for i in range(3):
        for j in range(10):
            if i == 0:  # RÂ²
                text = f'{performance_data[i, j]:.3f}'  # .3f thay vÃ¬ .4f
                color = 'white' if performance_data[i, j] < 0.95 else 'black'
            else:  # RMSE, MAE
                text = f'{performance_data[i, j]:.2f}'
                color = 'white' if performance_data[i, j] > performance_data[i].mean() else 'black'
            plt.text(j, i, text, ha='center', va='center', 
                    fontweight='bold', color=color, fontsize=9)
    
    plt.colorbar(im, label='Hiá»‡u suáº¥t (Xanh = Tá»‘t, Äá» = KÃ©m)')
    
    # Biá»ƒu Ä‘á»“ 6: Tá»•ng quan Ä‘á»™ á»•n Ä‘á»‹nh
    plt.subplot(2, 3, 6)
    metrics_std = [test_df['r2'].std(), test_df['rmse'].std(), test_df['mae'].std()]
    metrics_names = ['RÂ²', 'RMSE', 'MAE']
    colors_std = ['#2ECC71' if std < 0.02 else '#F39C12' if std < 0.05 else '#E74C3C' for std in metrics_std]
    
    bars = plt.bar(metrics_names, metrics_std, color=colors_std, alpha=0.7, edgecolor='black')
    plt.ylabel('Äá»™ lá»‡ch chuáº©n')
    plt.title('ÄÃNH GIÃ Äá»˜ á»”N Äá»ŠNH 10 Láº¦N CHáº Y', fontweight='bold', fontsize=14)
    plt.grid(True, alpha=0.3)
    
    # ThÃªm giÃ¡ trá»‹ vÃ  Ä‘Ã¡nh giÃ¡
    for bar, std, metric in zip(bars, metrics_std, metrics_names):
        if metric == 'RÂ²':
            rating = "Ráº¥t á»•n Ä‘á»‹nh" if std < 0.01 else "á»”n Ä‘á»‹nh" if std < 0.02 else "Biáº¿n Ä‘á»™ng"
        else:
            rating = "Ráº¥t á»•n Ä‘á»‹nh" if std < 0.5 else "á»”n Ä‘á»‹nh" if std < 1.0 else "Biáº¿n Ä‘á»™ng"
        
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, 
                 f'{std:.4f}\n{rating}', ha='center', va='bottom', 
                 fontweight='bold', fontsize=9)
    
    plt.tight_layout()
    plt.savefig(comparison_10_runs_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {comparison_10_runs_path}")

def create_detailed_runs_analysis(train_df, test_df, best_model_info):
    """Biá»ƒu Ä‘á»“ chi tiáº¿t tá»«ng láº§n cháº¡y"""
    print("ğŸ“Š 8. Biá»ƒu Ä‘á»“ chi tiáº¿t tá»«ng láº§n cháº¡y")
    
    # Äá»‹nh nghÄ©a cÃ¡c bá»™ tham sá»‘ (giá»‘ng trong model_trainer)
    param_sets = [
        {'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 10},
        {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 5},
        {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3},
        {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2},
        {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1},
        {'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 8},
        {'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4},
        {'max_depth': 6, 'min_samples_split': 25, 'min_samples_leaf': 12},
        {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 6},
        {'max_depth': 4, 'min_samples_split': 30, 'min_samples_leaf': 15}
    ]
    
    detailed_runs_path = os.path.join('img', 'detailed_runs_analysis.png')
    plt.figure(figsize=(20, 15))
    
    # Biá»ƒu Ä‘á»“ 1: Hiá»‡u suáº¥t theo max_depth
    plt.subplot(3, 3, 1)
    max_depths = [params.get('max_depth', 'None') for params in param_sets]
    test_r2_by_depth = test_df['r2'].values
    colors_depth = ['#2ECC71' if r2 > test_df['r2'].mean() else '#E74C3C' for r2 in test_r2_by_depth]
    
    bars = plt.bar(range(1, 11), test_r2_by_depth, color=colors_depth, alpha=0.7)
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('Test RÂ²')
    plt.title('HIá»†U SUáº¤T THEO Láº¦N CHáº Y', fontweight='bold')
    plt.xticks(range(1, 11), [f'Láº§n {i}' for i in range(1, 11)], rotation=45)
    plt.grid(True, alpha=0.3)
    
    # ThÃªm giÃ¡ trá»‹ RÂ²
    for i, (bar, r2, depth) in enumerate(zip(bars, test_r2_by_depth, max_depths)):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002, 
                 f'{r2:.3f}\n(depth: {depth})', ha='center', va='bottom', 
                 fontsize=8, fontweight='bold')
    
    # Biá»ƒu Ä‘á»“ 2: PhÃ¢n tÃ­ch tham sá»‘ max_depth
    plt.subplot(3, 3, 2)
    unique_depths = list(set(max_depths))
    depth_performance = []
    for depth in unique_depths:
        indices = [i for i, d in enumerate(max_depths) if d == depth]
        avg_r2 = test_df.iloc[indices]['r2'].mean()
        depth_performance.append(avg_r2)
    
    plt.bar([str(d) for d in unique_depths], depth_performance, 
            color='#3498DB', alpha=0.7, edgecolor='black')
    plt.xlabel('Max Depth')
    plt.ylabel('RÂ² Trung bÃ¬nh')
    plt.title('HIá»†U SUáº¤T THEO MAX DEPTH', fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    for i, (depth, perf) in enumerate(zip(unique_depths, depth_performance)):
        plt.text(i, perf + 0.002, f'{perf:.3f}', ha='center', va='bottom', 
                 fontweight='bold')
    
    # Biá»ƒu Ä‘á»“ 3: PhÃ¢n tÃ­ch min_samples_split
    plt.subplot(3, 3, 3)
    min_splits = [params.get('min_samples_split', 'N/A') for params in param_sets]
    split_groups = {}
    for i, split in enumerate(min_splits):
        if split not in split_groups:
            split_groups[split] = []
        split_groups[split].append(test_df.iloc[i]['r2'])
    
    split_means = {k: np.mean(v) for k, v in split_groups.items()}
    plt.bar([str(k) for k in split_means.keys()], split_means.values(),
            color='#9B59B6', alpha=0.7, edgecolor='black')
    plt.xlabel('Min Samples Split')
    plt.ylabel('RÂ² Trung bÃ¬nh')
    plt.title('HIá»†U SUáº¤T THEO MIN SAMPLES SPLIT', fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 4: TÆ°Æ¡ng quan giá»¯a cÃ¡c metrics
    plt.subplot(3, 3, 4)
    plt.scatter(test_df['rmse'], test_df['r2'], s=100, alpha=0.7, 
               c=test_df['r2'], cmap='RdYlGn')
    plt.xlabel('RMSE')
    plt.ylabel('RÂ²')
    plt.title('TÆ¯Æ NG QUAN RMSE vs RÂ²', fontweight='bold')
    plt.colorbar(label='RÂ² Score')
    plt.grid(True, alpha=0.3)
    
    # ThÃªm annotation cho cÃ¡c Ä‘iá»ƒm
    for i, (rmse, r2) in enumerate(zip(test_df['rmse'], test_df['r2'])):
        plt.annotate(f'Láº§n {i+1}', (rmse, r2), 
                    xytext=(5, 5), textcoords='offset points',
                    fontsize=8, alpha=0.8)
    
    # Biá»ƒu Ä‘á»“ 5: PhÃ¢n bá»‘ RÂ² cá»§a 10 láº§n cháº¡y
    plt.subplot(3, 3, 5)
    plt.hist(test_df['r2'], bins=8, color='#2ECC71', alpha=0.7, edgecolor='black')
    plt.axvline(test_df['r2'].mean(), color='red', linestyle='--', 
               label=f'Trung bÃ¬nh: {test_df["r2"].mean():.3f}')
    plt.xlabel('RÂ² Score')
    plt.ylabel('Táº§n suáº¥t')
    plt.title('PHÃ‚N Bá» RÂ² 10 Láº¦N CHáº Y', fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 6: Biá»ƒu Ä‘á»“ radar so sÃ¡nh metrics 
    plt.subplot(3, 3, 6, projection='polar')
    
    # Chuáº©n hÃ³a dá»¯ liá»‡u cho radar chart
    metrics_to_plot = ['r2', 'rmse', 'mae', 'mape']
    normalized_data = []
    for metric in metrics_to_plot:
        if metric == 'r2':  # RÂ² cÃ ng cao cÃ ng tá»‘t
            normalized = test_df[metric] / test_df[metric].max()
        else:  # RMSE, MAE, MAPE cÃ ng tháº¥p cÃ ng tá»‘t
            normalized = 1 - (test_df[metric] / test_df[metric].max())
        normalized_data.append(normalized.values)
    
    normalized_data = np.array(normalized_data)
    angles = np.linspace(0, 2*np.pi, len(metrics_to_plot), endpoint=False).tolist()
    angles += angles[:1]  # ÄÃ³ng vÃ²ng
    
    # Váº½ 3 láº§n cháº¡y tá»‘t nháº¥t
    best_runs_indices = test_df['r2'].nlargest(3).index
    colors_best = ['#E74C3C', '#3498DB', '#2ECC71']
    
    for idx, color in zip(best_runs_indices, colors_best):
        values = normalized_data[:, idx].tolist()
        values += values[:1]  # ÄÃ³ng vÃ²ng
        plt.plot(angles, values, 'o-', linewidth=2, label=f'Láº§n {idx+1}', color=color)
        plt.fill(angles, values, alpha=0.1, color=color)
    
    plt.thetagrids(np.degrees(angles[:-1]), metrics_to_plot)
    plt.title('RADAR CHART: 3 Láº¦N CHáº Y Tá»T NHáº¤T', fontweight='bold', pad=20)
    plt.legend(bbox_to_anchor=(1.3, 1.1))
    
    # Biá»ƒu Ä‘á»“ 7: Trend hiá»‡u suáº¥t theo thá»i gian
    plt.subplot(3, 3, 7)
    # TÃ­nh cumulative mean
    cumulative_mean = [test_df['r2'].iloc[:i+1].mean() for i in range(len(test_df))]
    cumulative_std = [test_df['r2'].iloc[:i+1].std() for i in range(len(test_df))]
    
    plt.plot(range(1, 11), cumulative_mean, marker='o', linewidth=2, 
             label='RÂ² trung bÃ¬nh tÃ­ch lÅ©y', color='#E74C3C')
    plt.fill_between(range(1, 11), 
                     np.array(cumulative_mean) - np.array(cumulative_std),
                     np.array(cumulative_mean) + np.array(cumulative_std),
                     alpha=0.2, color='#E74C3C', label='Â±1 std')
    plt.xlabel('Sá»‘ láº§n cháº¡y')
    plt.ylabel('RÂ² Trung bÃ¬nh tÃ­ch lÅ©y')
    plt.title('XU HÆ¯á»šNG HIá»†U SUáº¤T THEO Sá» Láº¦N CHáº Y', fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Biá»ƒu Ä‘á»“ 8: So sÃ¡nh Ä‘á»™ biáº¿n Ä‘á»™ng
    plt.subplot(3, 3, 8)
    metrics_variability = {
        'RÂ²': test_df['r2'].std(),
        'RMSE': test_df['rmse'].std(),
        'MAE': test_df['mae'].std(),
        'MAPE': test_df['mape'].std()
    }
    
    plt.bar(metrics_variability.keys(), metrics_variability.values(),
            color=['#2ECC71', '#3498DB', '#9B59B6', '#E67E22'], alpha=0.7)
    plt.ylabel('Äá»™ lá»‡ch chuáº©n')
    plt.title('Äá»˜ BIáº¾N Äá»˜NG CÃC CHá»ˆ Sá»', fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    for i, (metric, std) in enumerate(metrics_variability.items()):
        plt.text(i, std + 0.001, f'{std:.4f}', ha='center', va='bottom', 
                 fontweight='bold')
    
    # Biá»ƒu Ä‘á»“ 9: Tá»•ng káº¿t ranking
    plt.subplot(3, 3, 9)
    ranking = test_df['r2'].rank(ascending=False)
    colors_rank = ['gold' if rank == 1 else 'silver' if rank == 2 else 'brown' if rank == 3 else '#3498DB' 
                   for rank in ranking]
    
    plt.bar(range(1, 11), test_df['r2'], color=colors_rank, alpha=0.7)
    plt.xlabel('Láº§n cháº¡y')
    plt.ylabel('RÂ² Score')
    plt.title('RANKING 10 Láº¦N CHáº Y', fontweight='bold')
    plt.xticks(range(1, 11), [f'#{int(r)}' for r in ranking], rotation=45)
    
    for i, (r2, rank) in enumerate(zip(test_df['r2'], ranking)):
        medal = 'ğŸ¥‡' if rank == 1 else 'ğŸ¥ˆ' if rank == 2 else 'ğŸ¥‰' if rank == 3 else ''
        plt.text(i+1, r2 + 0.002, f'{r2:.3f}\n{medal}', ha='center', va='bottom', 
                 fontsize=8, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(detailed_runs_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {detailed_runs_path}")

def plot_decision_tree(best_model_info):
    """Váº½ vÃ  lÆ°u cÃ¢y quyáº¿t Ä‘á»‹nh"""
    print(f"\nğŸŒ³ 9. Váº½ vÃ  lÆ°u cÃ¢y quyáº¿t Ä‘á»‹nh")
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    tree_path = os.path.join('img', 'decision_tree.png')
    plt.figure(figsize=(25, 12))
    plot_tree(
        best_model_info['model'],
        feature_names=['AT', 'V', 'AP', 'RH'],
        filled=True,
        rounded=True,
        impurity=True,
        fontsize=8,
        max_depth=3
    )
    plt.title(f"CÃ‚Y QUYáº¾T Äá»ŠNH - MÃ” HÃŒNH Tá»T NHáº¤T (Láº§n {best_model_info['run_id'] + 1})", 
              fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(tree_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {tree_path}")

def plot_decision_tree_slide(X, y):
    """
    Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh tá»« 10 máº«u Ä‘áº§u tiÃªn (giá»‘ng slide)
    DÃ¹ng Ä‘á»ƒ minh há»a cÃ¡ch xÃ¢y dá»±ng cÃ¢y quyáº¿t Ä‘á»‹nh
    """
    print(f"\nğŸŒ³ Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh tá»« 10 máº«u Ä‘áº§u (cho slide)...")
    
    from sklearn.tree import DecisionTreeRegressor
    
    # Láº¥y 10 máº«u Ä‘áº§u tiÃªn
    X_sample = X.head(10)
    y_sample = y.head(10)
    
    # Táº¡o cÃ¢y quyáº¿t Ä‘á»‹nh vá»›i max_depth=3
    dt = DecisionTreeRegressor(max_depth=3, random_state=42)
    dt.fit(X_sample, y_sample)
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    tree_path = os.path.join('img', 'decision_tree_slide.png')
    
    plt.figure(figsize=(25, 12))
    plot_tree(
        dt,
        feature_names=['AT', 'V', 'AP', 'RH'],
        filled=True,
        rounded=True,
        impurity=True,
        fontsize=10,
        max_depth=3
    )
    plt.title("CÃ‚Y QUYáº¾T Äá»ŠNH - MINH Há»ŒA Tá»ª 10 MáºªU Äáº¦U TIÃŠN (CHO SLIDE)", 
              fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(tree_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {tree_path}")
    print(f"   ğŸ“Š Sá»­ dá»¥ng {len(X_sample)} máº«u Ä‘áº§u tiÃªn Ä‘á»ƒ minh há»a")
    
    return tree_path

def plot_decision_tree_simplified(best_model_info):
    """
    Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh rÃºt gá»n (max_depth=3) tá»« mÃ´ hÃ¬nh tá»‘t nháº¥t
    DÃ¹ng cho slide Ä‘á»ƒ dá»… nhÃ¬n hÆ¡n
    """
    print(f"\nğŸŒ³ Váº½ cÃ¢y quyáº¿t Ä‘á»‹nh rÃºt gá»n tá»« mÃ´ hÃ¬nh tá»‘t nháº¥t (cho slide)...")
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    tree_path = os.path.join('img', 'decision_tree_simplified.png')
    
    plt.figure(figsize=(25, 12))
    plot_tree(
        best_model_info['model'],
        feature_names=['AT', 'V', 'AP', 'RH'],
        filled=True,
        rounded=True,
        impurity=True,
        fontsize=10,
        max_depth=3  # Chá»‰ hiá»ƒn thá»‹ 3 cáº¥p Ä‘áº§u
    )
    plt.title(f"CÃ‚Y QUYáº¾T Äá»ŠNH RÃšT Gá»ŒN - MÃ” HÃŒNH Tá»T NHáº¤T (Láº§n {best_model_info['run_id'] + 1}, max_depth=3)", 
              fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(tree_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ÄÃ£ lÆ°u: {tree_path}")
    print(f"   ğŸ“Š CÃ¢y rÃºt gá»n (chá»‰ hiá»ƒn thá»‹ 3 cáº¥p Ä‘áº§u)")
    
    return tree_path

def create_comparison_3_methods_chart(best_models, test_df):
    """
    Táº¡o biá»ƒu Ä‘á»“ so sÃ¡nh 3 phÆ°Æ¡ng phÃ¡p (Decision Tree, Random Forest, Naive Bayes)
    qua 10 láº§n láº·p
    """
    print("\nğŸ“Š Táº¡o biá»ƒu Ä‘á»“ so sÃ¡nh 3 phÆ°Æ¡ng phÃ¡p qua 10 láº§n láº·p...")
    
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.naive_bayes import GaussianNB
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import f1_score, accuracy_score
    from improved.model_trainer_improved import calculate_metrics
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    
    # Sáº¯p xáº¿p best_models theo run_id
    sorted_models = sorted(best_models, key=lambda x: x['run_id'])
    
    # Chuáº©n bá»‹ dá»¯ liá»‡u cho 3 phÆ°Æ¡ng phÃ¡p
    dt_r2_scores = []
    rf_r2_scores = []
    nb_r2_scores = []
    nb_f1_scores = []  # F1 score cho Naive Bayes (classification)
    
    print("   Äang cháº¡y Random Forest vÃ  Naive Bayes cho 10 láº§n láº·p...")
    
    for i, model_info in enumerate(sorted_models):
        X_train = model_info['X_train']
        X_test = model_info['X_test']
        y_train = model_info['y_train']
        y_test = model_info['y_test']
        
        # Decision Tree RÂ² (Ä‘Ã£ cÃ³ sáºµn)
        dt_r2 = model_info['test_r2']
        dt_r2_scores.append(dt_r2)
        
        # Random Forest
        if isinstance(X_train, pd.DataFrame):
            X_train_array = X_train.values
        else:
            X_train_array = X_train
        
        if isinstance(y_train, pd.Series):
            y_train_array = y_train.values
        else:
            y_train_array = y_train
        
        rf_model = RandomForestRegressor(
            n_estimators=100, random_state=42+i, max_depth=10,
            min_samples_split=10, n_jobs=-1
        )
        rf_model.fit(X_train_array, y_train_array)
        y_pred_rf = rf_model.predict(X_test)
        rf_metrics = calculate_metrics(y_test, y_pred_rf)
        rf_r2_scores.append(rf_metrics['r2'])
        
        # Naive Bayes (Classification)
        # Chuáº©n hÃ³a dá»¯ liá»‡u
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_array)
        X_test_scaled = scaler.transform(X_test)
        
        # PhÃ¢n loáº¡i PE thÃ nh 3 lá»›p
        pe_q1 = np.percentile(y_train_array, 33.33)
        pe_q2 = np.percentile(y_train_array, 66.67)
        
        def classify_pe(value):
            if value < pe_q1:
                return 'Thap'
            elif value < pe_q2:
                return 'Trung binh'
            else:
                return 'Cao'
        
        y_train_class = np.array([classify_pe(val) for val in y_train_array])
        y_test_class = np.array([classify_pe(val) for val in y_test])
        
        # Huáº¥n luyá»‡n Naive Bayes
        nb_model = GaussianNB()
        nb_model.fit(X_train_scaled, y_train_class)
        y_pred_class = nb_model.predict(X_test_scaled)
        
        # TÃ­nh F1 score
        f1 = f1_score(y_test_class, y_pred_class, average='weighted')
        nb_f1_scores.append(f1)
        
        # TÃ­nh RÂ² (regression) cho Naive Bayes
        class_means = {
            'Thap': np.mean(y_train_array[y_train_class == 'Thap']) if np.sum(y_train_class == 'Thap') > 0 else pe_q1/2,
            'Trung binh': np.mean(y_train_array[y_train_class == 'Trung binh']) if np.sum(y_train_class == 'Trung binh') > 0 else (pe_q1 + pe_q2)/2,
            'Cao': np.mean(y_train_array[y_train_class == 'Cao']) if np.sum(y_train_class == 'Cao') > 0 else (pe_q2 + np.max(y_train_array))/2
        }
        y_pred_regression = np.array([class_means[pred] for pred in y_pred_class])
        nb_metrics = calculate_metrics(y_test, y_pred_regression)
        nb_r2_scores.append(nb_metrics['r2'])
        
        if (i + 1) % 2 == 0:
            print(f"      ÄÃ£ hoÃ n thÃ nh {i + 1}/10 láº§n láº·p...")
    
    # Táº¡o biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')
    
    # Kiá»ƒm tra dá»¯ liá»‡u
    print(f"   ğŸ“Š Sá»‘ lÆ°á»£ng Ä‘iá»ƒm dá»¯ liá»‡u:")
    print(f"      Decision Tree: {len(dt_r2_scores)}")
    print(f"      Random Forest: {len(rf_r2_scores)}")
    print(f"      Naive Bayes: {len(nb_r2_scores)}")
    
    # Äáº£m báº£o táº¥t cáº£ Ä‘á»u cÃ³ 10 giÃ¡ trá»‹
    if len(dt_r2_scores) != 10 or len(rf_r2_scores) != 10 or len(nb_r2_scores) != 10:
        print(f"   âš ï¸  Cáº£nh bÃ¡o: Sá»‘ lÆ°á»£ng Ä‘iá»ƒm dá»¯ liá»‡u khÃ´ng Ä‘á»u!")
        print(f"      DT: {len(dt_r2_scores)}, RF: {len(rf_r2_scores)}, NB: {len(nb_r2_scores)}")
    
    # Chuáº©n bá»‹ dá»¯ liá»‡u cho grouped bar chart
    runs = range(1, 11)
    x = np.arange(len(runs))
    width = 0.25  # Äá»™ rá»™ng cá»§a má»—i cá»™t
    
    # Váº½ cá»™t cho 3 phÆ°Æ¡ng phÃ¡p
    bars1 = ax.bar(x - width, dt_r2_scores, width, label='Decision Tree', 
                   color='#2ECC71', alpha=0.9, edgecolor='#27AE60', linewidth=2)
    bars2 = ax.bar(x, rf_r2_scores, width, label='Random Forest', 
                   color='#3498DB', alpha=0.9, edgecolor='#2980B9', linewidth=2)
    bars3 = ax.bar(x + width, nb_r2_scores, width, label='Naive Bayes', 
                  color='#E74C3C', alpha=0.9, edgecolor='#C0392B', linewidth=2)
    
    # ThÃªm giÃ¡ trá»‹ trÃªn má»—i cá»™t
    for bars in [bars1, bars2, bars3]:
        for bar in bars:
            height = bar.get_height()
            # Hiá»ƒn thá»‹ giÃ¡ trá»‹ cho táº¥t cáº£ cÃ¡c cá»™t
            ax.text(bar.get_x() + bar.get_width()/2, height + 0.005,
                   f'{height:.3f}',
                   ha='center', va='bottom',
                   fontsize=8, fontweight='bold')
    
    # Cáº¥u hÃ¬nh trá»¥c
    ax.set_xlabel('Láº§n láº·p', fontsize=14, fontweight='bold')
    ax.set_ylabel('RÂ² Score', fontsize=14, fontweight='bold')
    ax.set_title('BIá»‚U Äá»’ SO SÃNH Äá»˜ CHÃNH XÃC RÂ² Tá»”NG THá»‚ Cá»¦A 3 GIáº¢I THUáº¬T\n'
                 'Decision Tree, Random Forest, Naive Bayes - Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ sau 10 láº§n láº·p',
                 fontsize=16, fontweight='bold', pad=20)
    
    ax.set_xticks(x)
    ax.set_xticklabels([f'Láº§n láº·p {i}' for i in runs], fontsize=10)
    
    # Äiá»u chá»‰nh y-axis dá»±a trÃªn giÃ¡ trá»‹ thá»±c táº¿
    all_scores = dt_r2_scores + rf_r2_scores + nb_r2_scores
    min_score = min(all_scores)
    max_score = max(all_scores)
    y_min = max(0.0, min_score - 0.05)
    y_max = min(1.0, max_score + 0.05)
    ax.set_ylim(y_min, y_max)
    
    # Táº¡o yticks phÃ¹ há»£p
    y_ticks = np.arange(np.floor(y_min * 10) / 10, np.ceil(y_max * 10) / 10 + 0.01, 0.02)
    ax.set_yticks(y_ticks)
    ax.grid(True, alpha=0.3, axis='y', linestyle='--')
    ax.set_axisbelow(True)
    ax.legend(loc='upper left', fontsize=11, framealpha=0.9)
    
    # TÃ­nh RÂ² trung bÃ¬nh
    avg_dt_r2 = np.mean(dt_r2_scores)
    avg_rf_r2 = np.mean(rf_r2_scores)
    avg_nb_r2 = np.mean(nb_r2_scores)
    
    # ThÃªm text box vá»›i thÃ´ng tin
    info_text = f"RÂ² score trung bÃ¬nh:\n"
    info_text += f"Decision Tree: {avg_dt_r2:.3f}\n"
    info_text += f"Random Forest: {avg_rf_r2:.3f}\n"
    info_text += f"Naive Bayes: {avg_nb_r2:.3f}"
    
    ax.text(0.02, 0.98, info_text,
            transform=ax.transAxes, fontsize=11, fontweight='bold',
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='#F8F9FA', 
                     alpha=0.9, edgecolor='#34495E', linewidth=2))
    
    plt.tight_layout()
    
    # LÆ°u file
    output_path = os.path.join('img', 'comparison_3_methods_10_runs.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"   âœ… ÄÃ£ lÆ°u: {output_path}")
    print(f"   ğŸ“Š RÂ² score trung bÃ¬nh:")
    print(f"      Decision Tree: {avg_dt_r2:.3f}")
    print(f"      Random Forest: {avg_rf_r2:.3f}")
    print(f"      Naive Bayes: {avg_nb_r2:.3f}")
    
    return output_path

def create_r2_score_by_params_chart(best_models):
    """
    Táº¡o biá»ƒu Ä‘á»“ cá»™t RÂ² score theo cÃ¡c tham sá»‘ (max_depth, min_samples_leaf)
    Giá»‘ng nhÆ° trong slide
    """
    print("\nğŸ“Š Táº¡o biá»ƒu Ä‘á»“ RÂ² score theo cÃ¡c tham sá»‘...")
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    
    # Sáº¯p xáº¿p best_models theo run_id Ä‘á»ƒ Ä‘áº£m báº£o thá»© tá»± Ä‘Ãºng
    sorted_models = sorted(best_models, key=lambda x: x['run_id'])
    
    # Chuáº©n bá»‹ dá»¯ liá»‡u
    runs = []
    r2_scores = []
    labels = []
    
    for i, model_info in enumerate(sorted_models):
        params = model_info['params']
        r2 = model_info['test_r2']
        run_id = model_info['run_id']
        
        # Láº¥y cÃ¡c tham sá»‘
        random_state = 42 + run_id  # random_state trong code
        max_depth = params.get('max_depth', 'None')
        if max_depth is None:
            max_depth = 'None'
        min_samples_leaf = params.get('min_samples_leaf', 'N/A')
        
        runs.append(i + 1)
        r2_scores.append(r2)
        
        # Táº¡o label cho x-axis (3 dÃ²ng: RS, MD, MSL)
        labels.append(f"RS{random_state}.0\nMD{max_depth}.0\nMSL{min_samples_leaf}.0")
    
    # Táº¡o biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(16, 9))
    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')
    
    # Váº½ cá»™t
    bars = ax.bar(runs, r2_scores, color='#2ECC71', alpha=0.8, 
                  edgecolor='#27AE60', linewidth=2)
    
    # ThÃªm giÃ¡ trá»‹ RÂ² trÃªn má»—i cá»™t
    for bar, r2 in zip(bars, r2_scores):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, height + 0.005,
                f'{r2:.3f}',
                ha='center', va='bottom',
                fontsize=11, fontweight='bold')
    
    # Cáº¥u hÃ¬nh trá»¥c
    ax.set_xlabel('Cáº¥u hÃ¬nh tham sá»‘', fontsize=14, fontweight='bold')
    ax.set_ylabel('RÂ² Score', fontsize=14, fontweight='bold')
    ax.set_title('RÂ² SCORE Cá»¦A CÃ‚Y QUYáº¾T Äá»ŠNH Vá»šI CÃC THAM Sá» KHÃC NHAU\n'
                 'Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ sau 10 láº§n láº·p',
                 fontsize=16, fontweight='bold', pad=20)
    
    # Äáº·t nhÃ£n x-axis
    ax.set_xticks(runs)
    ax.set_xticklabels(labels, fontsize=9, rotation=0, ha='center')
    
    # Äiá»u chá»‰nh y-axis
    ax.set_ylim(0.9, 1.0)
    ax.set_yticks([0.9, 0.92, 0.94, 0.96, 0.98, 1.0])
    ax.grid(True, alpha=0.3, axis='y', linestyle='--')
    ax.set_axisbelow(True)
    
    # TÃ­nh RÂ² trung bÃ¬nh
    avg_r2 = np.mean(r2_scores)
    
    # ThÃªm text box vá»›i thÃ´ng tin
    info_text = f"Cáº¥u hÃ¬nh tham sá»‘\n=> RÂ² score trung bÃ¬nh: {avg_r2:.3f}"
    ax.text(0.02, 0.98, info_text,
            transform=ax.transAxes, fontsize=12, fontweight='bold',
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='#3498DB', 
                     alpha=0.9, edgecolor='#2980B9', linewidth=2),
            color='white')
    
    plt.tight_layout()
    
    # LÆ°u file
    output_path = os.path.join('img', 'r2_score_by_params.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"   âœ… ÄÃ£ lÆ°u: {output_path}")
    print(f"   ğŸ“Š RÂ² score trung bÃ¬nh: {avg_r2:.3f}")
    print(f"   ğŸ“Š RÂ² score min: {min(r2_scores):.3f}")
    print(f"   ğŸ“Š RÂ² score max: {max(r2_scores):.3f}")
    
    return output_path

def create_pe_distribution_slide(y):
    """
    Táº¡o biá»ƒu Ä‘á»“ phÃ¢n phá»‘i biáº¿n má»¥c tiÃªu PE cho slide
    
    Parameters:
    - y: Series hoáº·c array chá»©a giÃ¡ trá»‹ PE
    """
    print("\nğŸ“Š Táº¡o biá»ƒu Ä‘á»“ phÃ¢n phá»‘i PE cho slide...")
    
    # Äáº£m báº£o thÆ° má»¥c img tá»“n táº¡i
    os.makedirs('img', exist_ok=True)
    
    # Chuyá»ƒn Ä‘á»•i sang numpy array náº¿u cáº§n
    if hasattr(y, 'values'):
        pe = y.values
    else:
        pe = np.array(y)
    
    # Äá»‹nh nghÄ©a cÃ¡c bins nhÆ° trong slide
    bins = [440, 452, 468]
    bin_labels = ['< 440 MW', '440 - 452 MW', '452 - 468 MW', '>= 468 MW']
    
    # TÃ­nh sá»‘ lÆ°á»£ng vÃ  pháº§n trÄƒm cho má»—i bin
    counts = [
        np.sum(pe < 440),
        np.sum((pe >= 440) & (pe < 452)),
        np.sum((pe >= 452) & (pe < 468)),
        np.sum(pe >= 468)
    ]
    
    percentages = [count / len(pe) * 100 for count in counts]
    
    # Táº¡o biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(14, 8))
    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')
    
    # Váº½ bar chart
    bars = ax.bar(bin_labels, counts, color='#3498DB', alpha=0.8, 
                  edgecolor='black', linewidth=2)
    
    # ThÃªm giÃ¡ trá»‹ trÃªn má»—i cá»™t
    for bar, count, pct in zip(bars, counts, percentages):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, height + max(counts)*0.02,
                f'{count:,}\n({pct:.1f}%)',
                ha='center', va='bottom',
                fontsize=12, fontweight='bold')
    
    # Cáº¥u hÃ¬nh trá»¥c
    ax.set_ylabel('Sá»‘ lÆ°á»£ng (Count)', fontsize=14, fontweight='bold')
    ax.set_xlabel('GiÃ¡ trá»‹ nhÃ£n PE:', fontsize=14, fontweight='bold')
    ax.set_title('PHÃ‚N PHá»I BIáº¾N Má»¤C TIÃŠU: Sáº¢N LÆ¯á»¢NG ÄIá»†N (PE)', 
                 fontsize=16, fontweight='bold', pad=20)
    
    # Äiá»u chá»‰nh y-axis Ä‘á»ƒ cÃ³ khoáº£ng trá»‘ng cho text
    ax.set_ylim(0, max(counts) * 1.15)
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_axisbelow(True)
    
    # Bá» há»™p vÄƒn báº£n mÃ u vÃ ng vÃ¬ thÃ´ng tin Ä‘Ã£ cÃ³ trÃªn cÃ¡c cá»™t
    # ThÃ´ng tin chi tiáº¿t Ä‘Ã£ Ä‘Æ°á»£c hiá»ƒn thá»‹ trÃªn má»—i cá»™t
    
    plt.xticks(fontsize=11, rotation=0)
    plt.tight_layout()
    
    # LÆ°u file
    output_path = os.path.join('img', 'pe_distribution_slide.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"   âœ… ÄÃ£ lÆ°u: {output_path}")
    print(f"   ğŸ“Š Thá»‘ng kÃª:")
    print(f"      â€¢ Tá»•ng sá»‘ máº«u: {len(pe):,}")
    print(f"      â€¢ PE min: {np.min(pe):.2f} MW")
    print(f"      â€¢ PE max: {np.max(pe):.2f} MW")
    print(f"      â€¢ PE mean: {np.mean(pe):.2f} MW")
    print(f"      â€¢ PE median: {np.median(pe):.2f} MW")
    for label, count, pct in zip(bin_labels, counts, percentages):
        print(f"      â€¢ {label}: {count:,} ({pct:.1f}%)")
    
    return output_path