import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV, cross_validate
from model_trainer import calculate_metrics

def compare_with_other_models(X_train_best, X_test_best, y_train_best, y_test_best, best_model):
    """
    So sÃ¡nh Decision Tree vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c
    
    Returns:
    - comparison_results: dictionary chá»©a káº¿t quáº£ so sÃ¡nh
    """
    comparison_results = {}
    
    # TÃ­nh metrics cho Decision Tree tá»‘t nháº¥t
    y_pred_dt_best = best_model.predict(X_test_best)
    dt_metrics_best = calculate_metrics(y_test_best, y_pred_dt_best)
    comparison_results['decision_tree'] = {
        'metrics': dt_metrics_best,
        'predictions': y_pred_dt_best
    }
    
    # SO SÃNH Vá»šI RANDOM FOREST
    print("\nSO SÃNH Vá»šI RANDOM FOREST")
    rf_model = RandomForestRegressor(
        n_estimators=100, random_state=42, max_depth=10,
        min_samples_split=10, n_jobs=-1
    )
    rf_model.fit(X_train_best, y_train_best)
    y_pred_rf = rf_model.predict(X_test_best)
    rf_metrics = calculate_metrics(y_test_best, y_pred_rf)
    comparison_results['random_forest'] = {
        'metrics': rf_metrics,
        'predictions': y_pred_rf,
        'model': rf_model
    }
    
    # SO SÃNH Vá»šI KNN
    print("\nğŸ” SO SÃNH THÃŠM Vá»šI KNN REGRESSOR (Tá»I Æ¯U HÃ“A THAM Sá»)")
    knn_metrics, best_knn = train_optimized_knn(X_train_best, X_test_best, y_train_best, y_test_best)
    comparison_results['knn'] = {
        'metrics': knn_metrics,
        'predictions': knn_metrics.get('predictions'),
        'model': best_knn
    }
    
    # Cross-validation cho mÃ´ hÃ¬nh tá»‘t nháº¥t
    print("\nğŸ”„ ÄÃNH GIÃ Äá»˜ á»”N Äá»ŠNH Vá»šI CROSS-VALIDATION (5-fold)")
    cv_results = perform_cross_validation(best_model, X_train_best, y_train_best)
    comparison_results['cv_results'] = cv_results
    
    # In káº¿t quáº£ so sÃ¡nh
    print_comparison_results(dt_metrics_best, rf_metrics, knn_metrics, cv_results)
    
    return comparison_results

def train_optimized_knn(X_train, X_test, y_train, y_test):
    """Huáº¥n luyá»‡n KNN vá»›i tá»‘i Æ°u hÃ³a tham sá»‘"""
    knn_param_grid = {
        'n_neighbors': [3, 5, 7, 9, 11, 15],
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan', 'minkowski']
    }
    
    knn_grid = GridSearchCV(
        KNeighborsRegressor(), knn_param_grid, cv=5, 
        scoring='r2', n_jobs=-1, verbose=0
    )
    
    print("Äang tÃ¬m tham sá»‘ tá»‘i Æ°u cho KNN...")
    knn_grid.fit(X_train, y_train)
    
    best_knn = knn_grid.best_estimator_
    y_pred_knn = best_knn.predict(X_test)
    knn_metrics = calculate_metrics(y_test, y_pred_knn)
    knn_metrics['predictions'] = y_pred_knn
    
    print(f"\nâœ… KNN Regressor (ÄÃƒ Tá»I Æ¯U):")
    print(f"    Tham sá»‘ tá»‘t nháº¥t: {knn_grid.best_params_}")
    print(f"    RÂ²:   {knn_metrics['r2']:.4f}")
    print(f"    RMSE: {knn_metrics['rmse']:.4f}")
    
    return knn_metrics, best_knn

def perform_cross_validation(model, X, y):
    """Thá»±c hiá»‡n cross-validation"""
    cv_results = cross_validate(
        model, X, y, 
        cv=5, 
        scoring=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],
        return_train_score=True,
        n_jobs=-1
    )
    
    cv_train_r2 = cv_results['train_r2']
    cv_test_r2 = cv_results['test_r2']
    cv_test_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])
    cv_test_mae = -cv_results['test_neg_mean_absolute_error']
    
    return {
        'train_r2': cv_train_r2,
        'test_r2': cv_test_r2,
        'test_rmse': cv_test_rmse,
        'test_mae': cv_test_mae
    }

def print_comparison_results(dt_metrics, rf_metrics, knn_metrics, cv_results):
    """In káº¿t quáº£ so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh"""
    print("\n SO SÃNH HIá»†U SUáº¤T TRÃŠN Táº¬P TEST Tá»T NHáº¤T:")
    print(f"    Decision Tree (tá»‘t nháº¥t):")
    print(f"       RÂ²:   {dt_metrics['r2']:.4f}")
    print(f"       RMSE: {dt_metrics['rmse']:.4f}")
    print(f"       MAE:  {dt_metrics['mae']:.4f}")
    print(f"       MAPE: {dt_metrics['mape']:.2f}%")
    
    print(f"    Random Forest:")
    print(f"       RÂ²:   {rf_metrics['r2']:.4f}")
    print(f"       RMSE: {rf_metrics['rmse']:.4f}")
    print(f"       MAE:  {rf_metrics['mae']:.4f}")
    print(f"       MAPE: {rf_metrics['mape']:.2f}%")
    
    print(f"    KNN (tá»‘i Æ°u):")
    print(f"       RÂ²:   {knn_metrics['r2']:.4f}")
    print(f"       RMSE: {knn_metrics['rmse']:.4f}")
    print(f"       MAE:  {knn_metrics['mae']:.4f}")
    print(f"       MAPE: {knn_metrics['mape']:.2f}%")
    
    print(f"\nğŸ“Š Káº¾T QUáº¢ CROSS-VALIDATION (5-fold):")
    print(f"    Train RÂ²:     {cv_results['train_r2'].mean():.4f} (Â±{cv_results['train_r2'].std():.4f})")
    print(f"    Test RÂ²:      {cv_results['test_r2'].mean():.4f} (Â±{cv_results['test_r2'].std():.4f})")
    print(f"    Test RMSE:    {cv_results['test_rmse'].mean():.4f} (Â±{cv_results['test_rmse'].std():.4f})")
    
    cv_stability = "Ráº¤T á»”N Äá»ŠNH" if cv_results['test_r2'].std() < 0.02 else "KHÃ á»”N Äá»ŠNH" if cv_results['test_r2'].std() < 0.05 else "CÃ“ BIáº¾N Äá»˜NG"
    print(f"    Äá»™ á»•n Ä‘á»‹nh:    {cv_stability} (Ä‘á»™ lá»‡ch chuáº©n: {cv_results['test_r2'].std():.4f})")