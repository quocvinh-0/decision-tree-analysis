import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, learning_curve, GridSearchCV
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# ============================
# Táº O THÆ¯ Má»¤C LÆ¯U TRá»®
# ============================
os.makedirs('img', exist_ok=True)
os.makedirs('result', exist_ok=True)
print("âœ… ÄÃ£ táº¡o thÆ° má»¥c 'img' vÃ  'result'")

# ============================
# BÆ¯á»šC 1: Äá»ŒC VÃ€ KIá»‚M TRA Dá»® LIá»†U 
# ============================
print("PHÃ‚N TÃCH Dá»® LIá»†U Vá»šI CÃ‚Y QUYáº¾T Äá»ŠNH - Cáº¢I TIáº¾N (10 Láº¦N)")

try:
    xls = pd.ExcelFile('Folds5x2_pp.xlsx')
    df_list = []
    # Láº·p qua tÃªn cá»§a tá»«ng sheet
    for sheet_name in xls.sheet_names:
        print(f"Äang Ä‘á»c sheet: {sheet_name}...")
        df_list.append(pd.read_excel(xls, sheet_name=sheet_name))
    
    # Gá»™p táº¥t cáº£ cÃ¡c DataFrame tá»« cÃ¡c sheet láº¡i
    df = pd.concat(df_list, ignore_index=True)
    
    print(f" ÄÃ£ Ä‘á»c vÃ  gá»™p {len(xls.sheet_names)} sheets thÃ nh cÃ´ng!")
except FileNotFoundError:
    print(" Lá»–I: KhÃ´ng tÃ¬m tháº¥y file 'Folds5x2_pp.xlsx'.")
    print("Vui lÃ²ng Ä‘áº£m báº£o file dá»¯ liá»‡u náº±m cÃ¹ng thÆ° má»¥c vá»›i script.")
    exit()

print(f"\n THÃ”NG TIN DATASET (SAU KHI Gá»˜P):")
print(f"    . KÃ­ch thÆ°á»›c: {df.shape} ({df.shape[0]:,} máº«u Ã— {df.shape[1]} Ä‘áº·c trÆ°ng)")
print(f"     Cá»™t: {list(df.columns)}")
print(f"     Kiá»ƒm tra NaN (dá»¯ liá»‡u thiáº¿u): {df.isna().sum().sum()} (Náº¿u > 0 lÃ  cÃ³ lá»—i)")

# ============================
# BÆ¯á»šC 2: PHÃ‚N TÃCH VÃ€ TIá»€N Xá»¬ LÃ
# ============================
X = df[['AT', 'V', 'AP', 'RH']]
y = df['PE']

# BÆ¯á»šC 2.5: FEATURE ENGINEERING NÃ‚NG CAO
print("\nğŸ”§ FEATURE ENGINEERING NÃ‚NG CAO")

# Táº¡o cÃ¡c feature tÆ°Æ¡ng tÃ¡c vÃ  Ä‘a thá»©c
X_enhanced = X.copy()
X_enhanced['AT_V'] = X['AT'] * X['V']           # TÆ°Æ¡ng tÃ¡c nhiá»‡t Ä‘á»™ vÃ  Ã¡p suáº¥t hÆ¡i
X_enhanced['AT_RH'] = X['AT'] * X['RH']         # TÆ°Æ¡ng tÃ¡c nhiá»‡t Ä‘á»™ vÃ  Ä‘á»™ áº©m
X_enhanced['V_AP'] = X['V'] * X['AP']           # TÆ°Æ¡ng tÃ¡c Ã¡p suáº¥t hÆ¡i vÃ  Ã¡p suáº¥t khÃ­
X_enhanced['AT_squared'] = X['AT'] ** 2         # Äa thá»©c báº­c 2 cho nhiá»‡t Ä‘á»™
X_enhanced['V_squared'] = X['V'] ** 2           # Äa thá»©c báº­c 2 cho Ã¡p suáº¥t hÆ¡i

print(f"    Sá»‘ feature ban Ä‘áº§u: {X.shape[1]}")
print(f"    Sá»‘ feature sau engineering: {X_enhanced.shape[1]}")
print(f"    Feature má»›i: {list(X_enhanced.columns)[X.shape[1]:]}")

# ThÃªm lá»±a chá»n sá»­ dá»¥ng feature engineering (tÃ¹y chá»n)
use_enhanced_features = False  # Äá»•i thÃ nh True Ä‘á»ƒ dÃ¹ng feature má»›i

if use_enhanced_features:
    X = X_enhanced
    print("    âœ… ÄÃ£ sá»­ dá»¥ng feature engineering")
else:
    print("    â„¹ï¸  Sá»­ dá»¥ng feature gá»‘c (Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng)")

# ============================
# BÆ¯á»šC 3: Láº¶P 10 Láº¦N HUáº¤N LUYá»†N
# ============================
print("\nCáº¢I TIáº¾N: HUáº¤N LUYá»†N 10 Láº¦N VÃ€ TÃNH TRUNG BÃŒNH")

# Lists Ä‘á»ƒ lÆ°u káº¿t quáº£ cá»§a 10 láº§n cháº¡y
all_train_metrics = []
all_test_metrics = []
all_feature_importances = []
best_models = []

# Thá»­ nhiá»u bá»™ siÃªu tham sá»‘ khÃ¡c nhau
param_sets = [
    {'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 10},
    {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 5},
    {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3},
    {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2},
    {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1},
    {'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 8},
    {'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4},
    {'max_depth': 6, 'min_samples_split': 25, 'min_samples_leaf': 12},
    {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 6},
    {'max_depth': 4, 'min_samples_split': 30, 'min_samples_leaf': 15}
]

# HÃ m tÃ­nh metrics 
def calculate_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mse)
    # Xá»­ lÃ½ trÆ°á»ng há»£p y_true = 0 Ä‘á»ƒ trÃ¡nh lá»—i chia cho 0
    mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true != 0, y_true, 1e-10))) * 100
    
    return {
        'mse': mse, 'rmse': rmse, 'mae': mae, 
        'r2': r2, 'mape': mape
    }

for i in range(10):
    print(f"\nğŸ”„ Láº¦N CHáº Y THá»¨ {i+1}/10")
    
    # Chuáº©n hÃ³a dá»¯ liá»‡u cho má»—i láº§n cháº¡y
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # PhÃ¢n chia train-test vá»›i random_state khÃ¡c nhau
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=40 + i, shuffle=True
    )
    
    # Láº¥y bá»™ tham sá»‘ cho láº§n cháº¡y nÃ y
    params = param_sets[i]
    print(f"     Tham sá»‘: {params}")
    
    # Táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
    dt_model = DecisionTreeRegressor(
        random_state=40 + i,
        **params
    )
    
    dt_model.fit(X_train, y_train)
    
    # Dá»± Ä‘oÃ¡n
    y_pred_train = dt_model.predict(X_train)
    y_pred_test = dt_model.predict(X_test)
    
    # TÃ­nh metrics
    train_metrics = calculate_metrics(y_train, y_pred_train)
    test_metrics = calculate_metrics(y_test, y_pred_test)
    
    # LÆ°u káº¿t quáº£
    all_train_metrics.append(train_metrics)
    all_test_metrics.append(test_metrics)
    all_feature_importances.append(dt_model.feature_importances_)
    
    best_models.append({
        'model': dt_model,
        'params': params,
        'test_r2': test_metrics['r2'],
        'run_id': i,
        'X_train': X_train, 'y_train': y_train,
        'X_test': X_test, 'y_test': y_test,
        'y_pred_test': y_pred_test,
        'scaler': scaler
    })
    
    print(f"    âœ“ Train RÂ²: {train_metrics['r2']:.4f}")
    print(f"    âœ“ Test RÂ²:  {test_metrics['r2']:.4f}")
    print(f"    âœ“ Test RMSE: {test_metrics['rmse']:.4f}")

# ============================
# BÆ¯á»šC 4: PHÃ‚N TÃCH Káº¾T QUáº¢ 10 Láº¦N CHáº Y
# ============================
print("\n" + "="*50)
print("PHÃ‚N TÃCH Tá»”NG Há»¢P 10 Láº¦N CHáº Y")
print("="*50)

train_df = pd.DataFrame(all_train_metrics)
test_df = pd.DataFrame(all_test_metrics)

# TÃ­nh trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n
print("\n THá»NG KÃŠ Táº¬P TRAIN (10 láº§n):")
print(f"     RÂ²:     {train_df['r2'].mean():.4f} (Â±{train_df['r2'].std():.4f})")
print(f"     RMSE:   {train_df['rmse'].mean():.4f} (Â±{train_df['rmse'].std():.4f})")
print(f"     MSE:    {train_df['mse'].mean():.4f} (Â±{train_df['mse'].std():.4f})")
print(f"     MAE:    {train_df['mae'].mean():.4f} (Â±{train_df['mae'].std():.4f})")
print(f"     MAPE:   {train_df['mape'].mean():.2f}% (Â±{train_df['mape'].std():.2f}%)")

print("\n THá»NG KÃŠ Táº¬P TEST (10 láº§n):")
print(f"     RÂ²:     {test_df['r2'].mean():.4f} (Â±{test_df['r2'].std():.4f})")
print(f"     RMSE:   {test_df['rmse'].mean():.4f} (Â±{test_df['rmse'].std():.4f})")
print(f"     MSE:    {test_df['mse'].mean():.4f} (Â±{test_df['mse'].std():.4f})")
print(f"     MAE:    {test_df['mae'].mean():.4f} (Â±{test_df['mae'].std():.4f})")
print(f"     MAPE:   {test_df['mape'].mean():.2f}% (Â±{test_df['mape'].std():.2f}%)")

# TÃ­nh Ä‘á»™ quan trá»ng Ä‘áº·c trÆ°ng trung bÃ¬nh
avg_feature_importance = np.mean(all_feature_importances, axis=0)
feature_importance_df = pd.DataFrame({
    'Äáº·c trÆ°ng': ['AT', 'V', 'AP', 'RH'],
    'Äá»™ quan trá»ng trung bÃ¬nh': avg_feature_importance,
    'Äá»™ lá»‡ch chuáº©n': np.std(all_feature_importances, axis=0)
}).sort_values('Äá»™ quan trá»ng trung bÃ¬nh', ascending=False)

print("\n Äá»˜ QUAN TRá»ŒNG Äáº¶C TRÆ¯NG TRUNG BÃŒNH:")
for idx, row in feature_importance_df.iterrows():
    print(f"    âœ“ {row['Äáº·c trÆ°ng']}: {row['Äá»™ quan trá»ng trung bÃ¬nh']:.4f} (Â±{row['Äá»™ lá»‡ch chuáº©n']:.4f})")

# ============================
# BÆ¯á»šC 5: CHá»ŒN MÃ” HÃŒNH Tá»T NHáº¤T
# ============================
best_models.sort(key=lambda x: x['test_r2'], reverse=True)
best_model_info = best_models[0] 
best_model = best_model_info['model']

# LÆ°u mÃ´ hÃ¬nh vÃ  scaler
model_path = os.path.join('result', 'best_decision_tree_model.pkl')
scaler_path = os.path.join('result', 'scaler.pkl')
joblib.dump(best_model, model_path)
joblib.dump(best_model_info['scaler'], scaler_path)

print("\nâœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ  scaler thÃ nh cÃ´ng vÃ o thÆ° má»¥c 'result':")
print(f"   â€¢ {model_path}")
print(f"   â€¢ {scaler_path}")

print(f"\nğŸ† MÃ” HÃŒNH Tá»T NHáº¤T (Láº§n cháº¡y {best_model_info['run_id'] + 1}):")
print(f"     Tham sá»‘: {best_model_info['params']}")
print(f"     Test RÂ²: {best_model_info['test_r2']:.4f}")

# Láº¥y dá»¯ liá»‡u tá»« mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘á»ƒ so sÃ¡nh
X_train_best = best_model_info['X_train']
X_test_best = best_model_info['X_test'] 
y_train_best = best_model_info['y_train']
y_test_best = best_model_info['y_test']
y_pred_test_best = best_model_info['y_pred_test']

# ============================
# BÆ¯á»šC 5.5: CROSS-VALIDATION
# ============================
print("\nğŸ”„ ÄÃNH GIÃ Äá»˜ á»”N Äá»ŠNH Vá»šI CROSS-VALIDATION (5-fold)")

cv_results = cross_validate(
    best_model, X_scaled, y, 
    cv=5, 
    scoring=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],
    return_train_score=True,
    n_jobs=-1
)

cv_train_r2 = cv_results['train_r2']
cv_test_r2 = cv_results['test_r2']
cv_test_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])
cv_test_mae = -cv_results['test_neg_mean_absolute_error']

print(f"\nğŸ“Š Káº¾T QUáº¢ CROSS-VALIDATION (5-fold):")
print(f"    Train RÂ²:     {cv_train_r2.mean():.4f} (Â±{cv_train_r2.std():.4f})")
print(f"    Test RÂ²:      {cv_test_r2.mean():.4f} (Â±{cv_test_r2.std():.4f})")
print(f"    Test RMSE:    {cv_test_rmse.mean():.4f} (Â±{cv_test_rmse.std():.4f})")
print(f"    Test MAE:     {cv_test_mae.mean():.4f} (Â±{cv_test_mae.std():.4f})")

cv_stability = "Ráº¤T á»”N Äá»ŠNH" if cv_test_r2.std() < 0.02 else "KHÃ á»”N Äá»ŠNH" if cv_test_r2.std() < 0.05 else "CÃ“ BIáº¾N Äá»˜NG"
print(f"    Äá»™ á»•n Ä‘á»‹nh:    {cv_stability} (Ä‘á»™ lá»‡ch chuáº©n: {cv_test_r2.std():.4f})")

print(f"\nğŸ“ˆ SO SÃNH PHÆ¯Æ NG PHÃP:")
print(f"    10 láº§n split:  RÂ² = {test_df['r2'].mean():.4f} (Â±{test_df['r2'].std():.4f})")
print(f"    5-fold CV:     RÂ² = {cv_test_r2.mean():.4f} (Â±{cv_test_r2.std():.4f})")

# ============================
# BÆ¯á»šC 6: SO SÃNH Vá»šI MÃ” HÃŒNH KHÃC
# ============================
print("\nSO SÃNH Vá»šI RANDOM FOREST")

# Huáº¥n luyá»‡n Random Forest
rf_model = RandomForestRegressor(
    n_estimators=100, random_state=42, max_depth=10,
    min_samples_split=10, n_jobs=-1
)
rf_model.fit(X_train_best, y_train_best)
y_pred_rf = rf_model.predict(X_test_best)
rf_metrics = calculate_metrics(y_test_best, y_pred_rf)

# TÃ­nh metrics cho Decision Tree tá»‘t nháº¥t
y_pred_dt_best = best_model.predict(X_test_best)
dt_metrics_best = calculate_metrics(y_test_best, y_pred_dt_best)

print("\n SO SÃNH HIá»†U SUáº¤T TRÃŠN Táº¬P TEST Tá»T NHáº¤T:")
print(f"    Decision Tree (tá»‘t nháº¥t):")
print(f"       RÂ²:   {dt_metrics_best['r2']:.4f}")
print(f"       RMSE: {dt_metrics_best['rmse']:.4f}")
print(f"       MAE:  {dt_metrics_best['mae']:.4f}")
print(f"       MAPE: {dt_metrics_best['mape']:.2f}%")

print(f"    Random Forest:")
print(f"       RÂ²:   {rf_metrics['r2']:.4f}")
print(f"       RMSE: {rf_metrics['rmse']:.4f}")
print(f"       MAE:  {rf_metrics['mae']:.4f}")
print(f"       MAPE: {rf_metrics['mape']:.2f}%")

# SO SÃNH Vá»šI KNN
print("\nğŸ” SO SÃNH THÃŠM Vá»šI KNN REGRESSOR (Tá»I Æ¯U HÃ“A THAM Sá»)")

knn_param_grid = {
    'n_neighbors': [3, 5, 7, 9, 11, 15],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

knn_grid = GridSearchCV(
    KNeighborsRegressor(), knn_param_grid, cv=5, 
    scoring='r2', n_jobs=-1, verbose=0
)

print("Äang tÃ¬m tham sá»‘ tá»‘i Æ°u cho KNN...")
knn_grid.fit(X_train_best, y_train_best)

best_knn = knn_grid.best_estimator_
y_pred_knn = best_knn.predict(X_test_best)
knn_metrics = calculate_metrics(y_test_best, y_pred_knn)

print(f"\nâœ… KNN Regressor (ÄÃƒ Tá»I Æ¯U):")
print(f"    Tham sá»‘ tá»‘t nháº¥t: {knn_grid.best_params_}")
print(f"    RÂ²:   {knn_metrics['r2']:.4f}")
print(f"    RMSE: {knn_metrics['rmse']:.4f}")
print(f"    MAE:  {knn_metrics['mae']:.4f}")
print(f"    MAPE: {knn_metrics['mape']:.2f}%")

# ============================
# BÆ¯á»šC 7: TRá»°C QUAN HÃ“A Káº¾T QUáº¢
# ============================
print("\nğŸ¨ Báº®T Äáº¦U TRá»°C QUAN HÃ“A Káº¾T QUáº¢")

# 7.1 Biá»ƒu Ä‘á»“ so sÃ¡nh mÃ´ hÃ¬nh
print("\nğŸ“Š 1. Biá»ƒu Ä‘á»“ so sÃ¡nh mÃ´ hÃ¬nh")
comparison_path = os.path.join('img', 'model_comparison.png')
plt.figure(figsize=(10, 6))
models = ['Decision Tree', 'Random Forest', 'KNN']
r2_scores = [dt_metrics_best['r2'], rf_metrics['r2'], knn_metrics['r2']]
colors = ['#2ECC71', '#3498DB', '#9B59B6']

bars = plt.bar(models, r2_scores, color=colors, alpha=0.8, edgecolor='black')
plt.ylabel('RÂ² Score', fontsize=12)
plt.title('SO SÃNH HIá»†U SUáº¤T CÃC MÃ” HÃŒNH', fontweight='bold', fontsize=14)
plt.ylim(0.8, 1.0)
plt.grid(True, alpha=0.3)

for bar, score in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
             f'{score:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)

plt.tight_layout()
plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {comparison_path}")

# 7.2 Biá»ƒu Ä‘á»“ feature importance
print("ğŸ“Š 2. Biá»ƒu Ä‘á»“ feature importance")
feature_img_path = os.path.join('img', 'feature_importance.png')
plt.figure(figsize=(10, 6))
features = feature_importance_df['Äáº·c trÆ°ng']
importances = feature_importance_df['Äá»™ quan trá»ng trung bÃ¬nh']
std_dev = feature_importance_df['Äá»™ lá»‡ch chuáº©n']

bars = plt.bar(features, importances, yerr=std_dev, capsize=8, 
               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'], 
               alpha=0.8, edgecolor='black')
plt.ylabel('Äá»™ quan trá»ng trung bÃ¬nh', fontsize=12)
plt.title('Äá»˜ QUAN TRá»ŒNG Äáº¶C TRÆ¯NG (10 Láº¦N CHáº Y)', fontweight='bold', fontsize=14)
plt.xticks(fontsize=11)
plt.grid(True, alpha=0.3)

for bar, importance, std in zip(bars, importances, std_dev):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{importance:.3f} (Â±{std:.3f})', ha='center', va='bottom', 
             fontweight='bold', fontsize=10)

plt.tight_layout()
plt.savefig(feature_img_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {feature_img_path}")

# 7.3 Biá»ƒu Ä‘á»“ Actual vs Predicted
print("ğŸ“Š 3. Biá»ƒu Ä‘á»“ Actual vs Predicted")
actual_pred_path = os.path.join('img', 'actual_vs_predicted.png')
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.scatter(y_test_best, y_pred_dt_best, alpha=0.6, s=30, color='blue')
plt.plot([y_test_best.min(), y_test_best.max()], [y_test_best.min(), y_test_best.max()], 'r--', lw=2)
plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
plt.title(f'Decision Tree\nRÂ² = {dt_metrics_best["r2"]:.4f}')
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 2)
plt.scatter(y_test_best, y_pred_rf, alpha=0.6, s=30, color='green')
plt.plot([y_test_best.min(), y_test_best.max()], [y_test_best.min(), y_test_best.max()], 'r--', lw=2)
plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
plt.title(f'Random Forest\nRÂ² = {rf_metrics["r2"]:.4f}')
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 3)
plt.scatter(y_test_best, y_pred_knn, alpha=0.6, s=30, color='purple')
plt.plot([y_test_best.min(), y_test_best.max()], [y_test_best.min(), y_test_best.max()], 'r--', lw=2)
plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
plt.title(f'KNN\nRÂ² = {knn_metrics["r2"]:.4f}')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(actual_pred_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {actual_pred_path}")

# 7.4 Biá»ƒu Ä‘á»“ tá»•ng há»£p 10 láº§n cháº¡y
print("ğŸ“Š 4. Biá»ƒu Ä‘á»“ tá»•ng há»£p 10 láº§n cháº¡y")
summary_plots_path = os.path.join('img', 'summary_plots.png')
plt.figure(figsize=(20, 12))
plt.suptitle("PHÃ‚N TÃCH Tá»”NG Há»¢P 10 Láº¦N HUáº¤N LUYá»†N DECISION TREE", fontsize=20, fontweight='bold', y=1.03)

# Biá»ƒu Ä‘á»“ 1: So sÃ¡nh RÂ² qua 10 láº§n cháº¡y
plt.subplot(2, 3, 1)
runs = range(1, 11)
plt.plot(runs, train_df['r2'], marker='o', linewidth=2, markersize=8, label='Train RÂ²', color='#2ECC71')
plt.plot(runs, test_df['r2'], marker='s', linewidth=2, markersize=8, label='Test RÂ²', color='#E74C3C')
plt.axhline(y=test_df['r2'].mean(), color='red', linestyle='--', alpha=0.7, label=f"Test RÂ² TB: {test_df['r2'].mean():.3f}")
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('RÂ² Score')
plt.title('SO SÃNH RÂ² QUA 10 Láº¦N CHáº Y', fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 2: So sÃ¡nh RMSE qua 10 láº§n cháº¡y
plt.subplot(2, 3, 2)
plt.plot(runs, train_df['rmse'], marker='o', linewidth=2, markersize=8, label='Train RMSE', color='#3498DB')
plt.plot(runs, test_df['rmse'], marker='s', linewidth=2, markersize=8, label='Test RMSE', color='#F39C12')
plt.axhline(y=test_df['rmse'].mean(), color='orange', linestyle='--', alpha=0.7, label=f"Test RMSE TB: {test_df['rmse'].mean():.3f}")
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('RMSE')
plt.title('SO SÃNH RMSE QUA 10 Láº¦N CHáº Y', fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 3: PhÃ¢n bá»‘ RÂ² trÃªn táº­p test
plt.subplot(2, 3, 3)
sns.boxplot(data=[train_df['r2'], test_df['r2']], palette=['#AED6F1', '#FAD7A0'])
plt.xticks([0, 1], ['Train RÂ²', 'Test RÂ²'])
plt.ylabel('RÂ² Score')
plt.title('PHÃ‚N Bá» RÂ² SCORE (10 Láº¦N)', fontweight='bold')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 4: Hiá»‡u suáº¥t theo bá»™ tham sá»‘
plt.subplot(2, 3, 4)
param_names = [f"Set {i+1}" for i in range(10)]
test_r2_values = test_df['r2']
plt.scatter(param_names, test_r2_values, s=100, alpha=0.7, c=test_r2_values, cmap='viridis')
plt.axhline(y=test_r2_values.mean(), color='red', linestyle='--', label='Trung bÃ¬nh')
plt.xlabel('Bá»™ tham sá»‘')
plt.ylabel('Test RÂ²')
plt.title('HIá»†U SUáº¤T THEO Bá»˜ THAM Sá»', fontweight='bold')
plt.xticks(rotation=45, ha='right')
plt.colorbar(label='RÂ² Score')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 5: So sÃ¡nh 3 mÃ´ hÃ¬nh
plt.subplot(2, 3, 5)
models_compare = ['DT', 'RF', 'KNN']
r2_compare = [dt_metrics_best['r2'], rf_metrics['r2'], knn_metrics['r2']]
plt.bar(models_compare, r2_compare, color=['#2ECC71', '#3498DB', '#9B59B6'])
plt.ylabel('RÂ² Score')
plt.title('SO SÃNH 3 MÃ” HÃŒNH', fontweight='bold')
for i, v in enumerate(r2_compare):
    plt.text(i, v + 0.005, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 6: Cross-validation results
plt.subplot(2, 3, 6)
cv_folds = range(1, 6)
plt.plot(cv_folds, cv_test_r2, marker='o', linewidth=2, markersize=8, color='#E74C3C')
plt.axhline(y=cv_test_r2.mean(), color='red', linestyle='--', label=f'Trung bÃ¬nh: {cv_test_r2.mean():.3f}')
plt.xlabel('Fold')
plt.ylabel('Test RÂ²')
plt.title('CROSS-VALIDATION (5-fold)', fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig(summary_plots_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {summary_plots_path}")

# 7.5 PhÃ¢n tÃ­ch sai sá»‘ (Residuals Analysis)
print("ğŸ“Š 5. PhÃ¢n tÃ­ch sai sá»‘")
residuals_dt = y_test_best - y_pred_dt_best
residuals_rf = y_test_best - y_pred_rf
residuals_knn = y_test_best - y_pred_knn

residuals_path = os.path.join('img', 'residuals_analysis.png')
plt.figure(figsize=(18, 12))

# Biá»ƒu Ä‘á»“ 1: Residuals vs Predicted cho DT
plt.subplot(2, 3, 1)
plt.scatter(y_pred_dt_best, residuals_dt, alpha=0.6, s=30, color='blue')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
plt.ylabel('Sai sá»‘ (Residuals)')
plt.title(f'Decision Tree\nStd: {residuals_dt.std():.3f}')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 2: Residuals vs Predicted cho RF
plt.subplot(2, 3, 2)
plt.scatter(y_pred_rf, residuals_rf, alpha=0.6, s=30, color='green')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
plt.ylabel('Sai sá»‘ (Residuals)')
plt.title(f'Random Forest\nStd: {residuals_rf.std():.3f}')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 3: Residuals vs Predicted cho KNN
plt.subplot(2, 3, 3)
plt.scatter(y_pred_knn, residuals_knn, alpha=0.6, s=30, color='purple')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
plt.ylabel('Sai sá»‘ (Residuals)')
plt.title(f'KNN\nStd: {residuals_knn.std():.3f}')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 4: PhÃ¢n phá»‘i residuals
plt.subplot(2, 3, 4)
plt.hist(residuals_dt, bins=30, alpha=0.7, label=f'DT (std: {residuals_dt.std():.3f})', color='blue')
plt.hist(residuals_rf, bins=30, alpha=0.7, label=f'RF (std: {residuals_rf.std():.3f})', color='green')
plt.hist(residuals_knn, bins=30, alpha=0.7, label=f'KNN (std: {residuals_knn.std():.3f})', color='purple')
plt.xlabel('Sai sá»‘ (Residuals)')
plt.ylabel('Táº§n suáº¥t')
plt.title('PHÃ‚N PHá»I SAI Sá» Cá»¦A CÃC MÃ” HÃŒNH')
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 5: Q-Q plot cho Decision Tree
plt.subplot(2, 3, 5)
stats.probplot(residuals_dt, dist="norm", plot=plt)
plt.title('Q-Q Plot: Decision Tree Residuals')

# Biá»ƒu Ä‘á»“ 6: So sÃ¡nh Ä‘á»™ lá»›n sai sá»‘
plt.subplot(2, 3, 6)
residuals_abs = [np.abs(residuals_dt).mean(), np.abs(residuals_rf).mean(), np.abs(residuals_knn).mean()]
models_resid = ['Decision Tree', 'Random Forest', 'KNN']
bars = plt.bar(models_resid, residuals_abs, color=['blue', 'green', 'purple'], alpha=0.7)
plt.ylabel('Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh (MAE)')
plt.title('SO SÃNH Äá»˜ Lá»šN SAI Sá»')
for bar, value in zip(bars, residuals_abs):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{value:.3f}', 
             ha='center', va='bottom', fontweight='bold')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(residuals_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {residuals_path}")

# PhÃ¢n tÃ­ch thá»‘ng kÃª residuals
print(f"\nğŸ“Š PHÃ‚N TÃCH THá»NG KÃŠ SAI Sá»:")
print(f"    Decision Tree: Mean = {residuals_dt.mean():.4f}, Std = {residuals_dt.std():.4f}")
print(f"    Random Forest: Mean = {residuals_rf.mean():.4f}, Std = {residuals_rf.std():.4f}")
print(f"    KNN:           Mean = {residuals_knn.mean():.4f}, Std = {residuals_knn.std():.4f}")

# 7.6 Learning Curves
print("ğŸ“Š 6. Learning Curves")

def plot_and_save_learning_curve(estimator, title, filename, X, y, cv=5):
    plt.figure(figsize=(10, 6))
    
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='r2', n_jobs=-1, random_state=42
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)
    
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_mean, 'o-', color="r", label="Training score", linewidth=2)
    plt.plot(train_sizes, test_mean, 'o-', color="g", label="Cross-validation score", linewidth=2)
    
    plt.xlabel("Sá»‘ lÆ°á»£ng máº«u training", fontsize=12)
    plt.ylabel("RÂ² Score", fontsize=12)
    plt.title(f"Learning Curve: {title}", fontweight='bold')
    plt.legend(loc="best")
    plt.grid(True, alpha=0.3)
    
    filepath = os.path.join('img', filename)
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   âœ… ÄÃ£ lÆ°u: {filepath}")
    return train_sizes, train_mean, test_mean

print("Äang váº½ vÃ  lÆ°u learning curves...")
plot_and_save_learning_curve(best_model, "Decision Tree (Best Model)", "learning_curve_dt.png", X_scaled, y)
plot_and_save_learning_curve(rf_model, "Random Forest", "learning_curve_rf.png", X_scaled, y)
# 7.7 Biá»ƒu Ä‘á»“ so sÃ¡nh chi tiáº¿t 10 láº§n láº·p
print("ğŸ“Š 7. Biá»ƒu Ä‘á»“ so sÃ¡nh chi tiáº¿t 10 láº§n láº·p")

comparison_10_runs_path = os.path.join('img', 'comparison_10_runs.png')
plt.figure(figsize=(18, 12))

# Biá»ƒu Ä‘á»“ 1: So sÃ¡nh RÂ² train vs test qua 10 láº§n
plt.subplot(2, 3, 1)
runs = range(1, 11)
plt.plot(runs, train_df['r2'], marker='o', linewidth=3, markersize=8, 
         label=f'Train RÂ² (TB: {train_df["r2"].mean():.4f})', color='#2ECC71')
plt.plot(runs, test_df['r2'], marker='s', linewidth=3, markersize=8, 
         label=f'Test RÂ² (TB: {test_df["r2"].mean():.4f})', color='#E74C3C')
plt.axhline(y=train_df['r2'].mean(), color='#2ECC71', linestyle='--', alpha=0.5)
plt.axhline(y=test_df['r2'].mean(), color='#E74C3C', linestyle='--', alpha=0.5)
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('RÂ² Score')
plt.title('SO SÃNH RÂ² TRAIN vs TEST QUA 10 Láº¦N', fontweight='bold', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.ylim(0.8, 1.0)

# ThÃªm annotation cho láº§n cháº¡y tá»‘t nháº¥t
best_run = best_model_info['run_id'] + 1
best_test_r2 = best_model_info['test_r2']
plt.annotate(f'Tá»‘t nháº¥t\nLáº§n {best_run}\nRÂ² = {best_test_r2:.4f}', 
             xy=(best_run, best_test_r2), 
             xytext=(best_run+0.5, best_test_r2-0.02),
             arrowprops=dict(arrowstyle='->', color='red', lw=2),
             fontweight='bold', color='red')

# Biá»ƒu Ä‘á»“ 2: So sÃ¡nh RMSE train vs test qua 10 láº§n
plt.subplot(2, 3, 2)
plt.plot(runs, train_df['rmse'], marker='o', linewidth=3, markersize=8, 
         label=f'Train RMSE (TB: {train_df["rmse"].mean():.4f})', color='#3498DB')
plt.plot(runs, test_df['rmse'], marker='s', linewidth=3, markersize=8, 
         label=f'Test RMSE (TB: {test_df["rmse"].mean():.4f})', color='#F39C12')
plt.axhline(y=train_df['rmse'].mean(), color='#3498DB', linestyle='--', alpha=0.5)
plt.axhline(y=test_df['rmse'].mean(), color='#F39C12', linestyle='--', alpha=0.5)
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('RMSE')
plt.title('SO SÃNH RMSE TRAIN vs TEST QUA 10 Láº¦N', fontweight='bold', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 3: So sÃ¡nh MAE train vs test qua 10 láº§n
plt.subplot(2, 3, 3)
plt.plot(runs, train_df['mae'], marker='o', linewidth=3, markersize=8, 
         label=f'Train MAE (TB: {train_df["mae"].mean():.4f})', color='#9B59B6')
plt.plot(runs, test_df['mae'], marker='s', linewidth=3, markersize=8, 
         label=f'Test MAE (TB: {test_df["mae"].mean():.4f})', color='#E67E22')
plt.axhline(y=train_df['mae'].mean(), color='#9B59B6', linestyle='--', alpha=0.5)
plt.axhline(y=test_df['mae'].mean(), color='#E67E22', linestyle='--', alpha=0.5)
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('MAE')
plt.title('SO SÃNH MAE TRAIN vs TEST QUA 10 Láº¦N', fontweight='bold', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 4: PhÃ¢n bá»‘ chÃªnh lá»‡ch RÂ² (Overfitting)
plt.subplot(2, 3, 4)
r2_diff = train_df['r2'] - test_df['r2']
plt.bar(runs, r2_diff, color=np.where(r2_diff > 0.1, '#E74C3C', '#2ECC71'), alpha=0.7)
plt.axhline(y=r2_diff.mean(), color='red', linestyle='--', 
           label=f'Trung bÃ¬nh: {r2_diff.mean():.4f}')
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('ChÃªnh lá»‡ch RÂ² (Train - Test)')
plt.title('ÄÃNH GIÃ OVERFITTING QUA 10 Láº¦N', fontweight='bold', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# ThÃªm giÃ¡ trá»‹ trÃªn cÃ¡c cá»™t
for i, v in enumerate(r2_diff):
    plt.text(i+1, v + 0.001, f'{v:.4f}', ha='center', va='bottom', 
             fontsize=9, fontweight='bold', 
             color='red' if v > 0.1 else 'green')

# Biá»ƒu Ä‘á»“ 5: Hiá»‡u suáº¥t theo bá»™ tham sá»‘ (Heatmap style)
plt.subplot(2, 3, 5)
# Táº¡o dá»¯ liá»‡u cho heatmap
param_names = [f"Láº§n {i+1}" for i in range(10)]
metrics = ['RÂ²', 'RMSE', 'MAE']
performance_data = np.array([
    test_df['r2'].values,
    test_df['rmse'].values,
    test_df['mae'].values
])

im = plt.imshow(performance_data, cmap='RdYlGn', aspect='auto')
plt.xticks(range(10), param_names, rotation=45)
plt.yticks(range(3), metrics)
plt.title('MA TRáº¬N HIá»†U SUáº¤T 10 Láº¦N CHáº Y', fontweight='bold', fontsize=14)

# ThÃªm giÃ¡ trá»‹ vÃ o Ã´ - Sá»¬A Äá»”I: RÂ² hiá»ƒn thá»‹ 3 chá»¯ sá»‘ tháº­p phÃ¢n
for i in range(3):
    for j in range(10):
        if i == 0:  # RÂ²
            text = f'{performance_data[i, j]:.3f}'  # ÄÃƒ Sá»¬A: .4f thÃ nh .3f
            color = 'white' if performance_data[i, j] < 0.95 else 'black'
        else:  # RMSE, MAE
            text = f'{performance_data[i, j]:.2f}'
            color = 'white' if performance_data[i, j] > performance_data[i].mean() else 'black'
        plt.text(j, i, text, ha='center', va='center', 
                fontweight='bold', color=color, fontsize=9)

plt.colorbar(im, label='Hiá»‡u suáº¥t (Xanh = Tá»‘t, Äá» = KÃ©m)')
# Biá»ƒu Ä‘á»“ 6: Tá»•ng quan Ä‘á»™ á»•n Ä‘á»‹nh
plt.subplot(2, 3, 6)
metrics_std = [test_df['r2'].std(), test_df['rmse'].std(), test_df['mae'].std()]
metrics_names = ['RÂ²', 'RMSE', 'MAE']
colors_std = ['#2ECC71' if std < 0.02 else '#F39C12' if std < 0.05 else '#E74C3C' for std in metrics_std]

bars = plt.bar(metrics_names, metrics_std, color=colors_std, alpha=0.7, edgecolor='black')
plt.ylabel('Äá»™ lá»‡ch chuáº©n')
plt.title('ÄÃNH GIÃ Äá»˜ á»”N Äá»ŠNH 10 Láº¦N CHáº Y', fontweight='bold', fontsize=14)
plt.grid(True, alpha=0.3)

# ThÃªm giÃ¡ trá»‹ vÃ  Ä‘Ã¡nh giÃ¡
for bar, std, metric in zip(bars, metrics_std, metrics_names):
    if metric == 'RÂ²':
        rating = "Ráº¥t á»•n Ä‘á»‹nh" if std < 0.01 else "á»”n Ä‘á»‹nh" if std < 0.02 else "Biáº¿n Ä‘á»™ng"
    else:
        rating = "Ráº¥t á»•n Ä‘á»‹nh" if std < 0.5 else "á»”n Ä‘á»‹nh" if std < 1.0 else "Biáº¿n Ä‘á»™ng"
    
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, 
             f'{std:.4f}\n{rating}', ha='center', va='bottom', 
             fontweight='bold', fontsize=9)

plt.tight_layout()
plt.savefig(comparison_10_runs_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {comparison_10_runs_path}")
# 7.8 Biá»ƒu Ä‘á»“ chi tiáº¿t tá»«ng láº§n cháº¡y vá»›i tham sá»‘
print("ğŸ“Š 8. Biá»ƒu Ä‘á»“ chi tiáº¿t tá»«ng láº§n cháº¡y")

detailed_runs_path = os.path.join('img', 'detailed_runs_analysis.png')
plt.figure(figsize=(20, 15))

# Biá»ƒu Ä‘á»“ 1: Hiá»‡u suáº¥t theo max_depth
plt.subplot(3, 3, 1)
max_depths = [params.get('max_depth', 'None') for params in param_sets]
test_r2_by_depth = test_df['r2'].values
colors_depth = ['#2ECC71' if r2 > test_df['r2'].mean() else '#E74C3C' for r2 in test_r2_by_depth]

bars = plt.bar(range(1, 11), test_r2_by_depth, color=colors_depth, alpha=0.7)
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('Test RÂ²')
plt.title('HIá»†U SUáº¤T THEO Láº¦N CHáº Y', fontweight='bold')
plt.xticks(range(1, 11), [f'Láº§n {i}' for i in range(1, 11)], rotation=45)
plt.grid(True, alpha=0.3)

# ThÃªm giÃ¡ trá»‹ RÂ²
for i, (bar, r2, depth) in enumerate(zip(bars, test_r2_by_depth, max_depths)):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002, 
             f'{r2:.4f}\n(depth: {depth})', ha='center', va='bottom', 
             fontsize=8, fontweight='bold')

# Biá»ƒu Ä‘á»“ 2: PhÃ¢n tÃ­ch tham sá»‘ max_depth
plt.subplot(3, 3, 2)
unique_depths = list(set(max_depths))
depth_performance = []
for depth in unique_depths:
    indices = [i for i, d in enumerate(max_depths) if d == depth]
    avg_r2 = test_df.iloc[indices]['r2'].mean()
    depth_performance.append(avg_r2)

plt.bar([str(d) for d in unique_depths], depth_performance, 
        color='#3498DB', alpha=0.7, edgecolor='black')
plt.xlabel('Max Depth')
plt.ylabel('RÂ² Trung bÃ¬nh')
plt.title('HIá»†U SUáº¤T THEO MAX DEPTH', fontweight='bold')
plt.grid(True, alpha=0.3)

for i, (depth, perf) in enumerate(zip(unique_depths, depth_performance)):
    plt.text(i, perf + 0.002, f'{perf:.4f}', ha='center', va='bottom', 
             fontweight='bold')

# Biá»ƒu Ä‘á»“ 3: PhÃ¢n tÃ­ch min_samples_split
plt.subplot(3, 3, 3)
min_splits = [params.get('min_samples_split', 'N/A') for params in param_sets]
split_groups = {}
for i, split in enumerate(min_splits):
    if split not in split_groups:
        split_groups[split] = []
    split_groups[split].append(test_df.iloc[i]['r2'])

split_means = {k: np.mean(v) for k, v in split_groups.items()}
plt.bar([str(k) for k in split_means.keys()], split_means.values(),
        color='#9B59B6', alpha=0.7, edgecolor='black')
plt.xlabel('Min Samples Split')
plt.ylabel('RÂ² Trung bÃ¬nh')
plt.title('HIá»†U SUáº¤T THEO MIN SAMPLES SPLIT', fontweight='bold')
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 4: TÆ°Æ¡ng quan giá»¯a cÃ¡c metrics
plt.subplot(3, 3, 4)
plt.scatter(test_df['rmse'], test_df['r2'], s=100, alpha=0.7, 
           c=test_df['r2'], cmap='RdYlGn')
plt.xlabel('RMSE')
plt.ylabel('RÂ²')
plt.title('TÆ¯Æ NG QUAN RMSE vs RÂ²', fontweight='bold')
plt.colorbar(label='RÂ² Score')
plt.grid(True, alpha=0.3)

# ThÃªm annotation cho cÃ¡c Ä‘iá»ƒm
for i, (rmse, r2) in enumerate(zip(test_df['rmse'], test_df['r2'])):
    plt.annotate(f'Láº§n {i+1}', (rmse, r2), 
                xytext=(5, 5), textcoords='offset points',
                fontsize=8, alpha=0.8)

# Biá»ƒu Ä‘á»“ 5: PhÃ¢n bá»‘ RÂ² cá»§a 10 láº§n cháº¡y
plt.subplot(3, 3, 5)
plt.hist(test_df['r2'], bins=8, color='#2ECC71', alpha=0.7, edgecolor='black')
plt.axvline(test_df['r2'].mean(), color='red', linestyle='--', 
           label=f'Trung bÃ¬nh: {test_df["r2"].mean():.4f}')
plt.xlabel('RÂ² Score')
plt.ylabel('Táº§n suáº¥t')
plt.title('PHÃ‚N Bá» RÂ² 10 Láº¦N CHáº Y', fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 6: Biá»ƒu Ä‘á»“ radar so sÃ¡nh metrics 
plt.subplot(3, 3, 6, projection='polar')  # THÃŠM projection='polar'

# Chuáº©n hÃ³a dá»¯ liá»‡u cho radar chart
metrics_to_plot = ['r2', 'rmse', 'mae', 'mape']
normalized_data = []
for metric in metrics_to_plot:
    if metric == 'r2':  # RÂ² cÃ ng cao cÃ ng tá»‘t
        normalized = test_df[metric] / test_df[metric].max()
    else:  # RMSE, MAE, MAPE cÃ ng tháº¥p cÃ ng tá»‘t
        normalized = 1 - (test_df[metric] / test_df[metric].max())
    normalized_data.append(normalized.values)

normalized_data = np.array(normalized_data)
angles = np.linspace(0, 2*np.pi, len(metrics_to_plot), endpoint=False).tolist()
angles += angles[:1]  # ÄÃ³ng vÃ²ng

# Váº½ 3 láº§n cháº¡y tá»‘t nháº¥t
best_runs_indices = test_df['r2'].nlargest(3).index
colors_best = ['#E74C3C', '#3498DB', '#2ECC71']

for idx, color in zip(best_runs_indices, colors_best):
    values = normalized_data[:, idx].tolist()
    values += values[:1]  # ÄÃ³ng vÃ²ng
    plt.plot(angles, values, 'o-', linewidth=2, label=f'Láº§n {idx+1}', color=color)
    plt.fill(angles, values, alpha=0.1, color=color)

plt.thetagrids(np.degrees(angles[:-1]), metrics_to_plot)
plt.title('RADAR CHART: 3 Láº¦N CHáº Y Tá»T NHáº¤T', fontweight='bold', pad=20)
plt.legend(bbox_to_anchor=(1.3, 1.1))
# Biá»ƒu Ä‘á»“ 7: Trend hiá»‡u suáº¥t theo thá»i gian
plt.subplot(3, 3, 7)
# TÃ­nh cumulative mean
cumulative_mean = [test_df['r2'].iloc[:i+1].mean() for i in range(len(test_df))]
cumulative_std = [test_df['r2'].iloc[:i+1].std() for i in range(len(test_df))]

plt.plot(range(1, 11), cumulative_mean, marker='o', linewidth=2, 
         label='RÂ² trung bÃ¬nh tÃ­ch lÅ©y', color='#E74C3C')
plt.fill_between(range(1, 11), 
                 np.array(cumulative_mean) - np.array(cumulative_std),
                 np.array(cumulative_mean) + np.array(cumulative_std),
                 alpha=0.2, color='#E74C3C', label='Â±1 std')
plt.xlabel('Sá»‘ láº§n cháº¡y')
plt.ylabel('RÂ² Trung bÃ¬nh tÃ­ch lÅ©y')
plt.title('XU HÆ¯á»šNG HIá»†U SUáº¤T THEO Sá» Láº¦N CHáº Y', fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# Biá»ƒu Ä‘á»“ 8: So sÃ¡nh Ä‘á»™ biáº¿n Ä‘á»™ng
plt.subplot(3, 3, 8)
metrics_variability = {
    'RÂ²': test_df['r2'].std(),
    'RMSE': test_df['rmse'].std(),
    'MAE': test_df['mae'].std(),
    'MAPE': test_df['mape'].std()
}

plt.bar(metrics_variability.keys(), metrics_variability.values(),
        color=['#2ECC71', '#3498DB', '#9B59B6', '#E67E22'], alpha=0.7)
plt.ylabel('Äá»™ lá»‡ch chuáº©n')
plt.title('Äá»˜ BIáº¾N Äá»˜NG CÃC CHá»ˆ Sá»', fontweight='bold')
plt.grid(True, alpha=0.3)

for i, (metric, std) in enumerate(metrics_variability.items()):
    plt.text(i, std + 0.001, f'{std:.4f}', ha='center', va='bottom', 
             fontweight='bold')

# Biá»ƒu Ä‘á»“ 9: Tá»•ng káº¿t ranking
plt.subplot(3, 3, 9)
ranking = test_df['r2'].rank(ascending=False)
colors_rank = ['gold' if rank == 1 else 'silver' if rank == 2 else 'brown' if rank == 3 else '#3498DB' 
               for rank in ranking]

plt.bar(range(1, 11), test_df['r2'], color=colors_rank, alpha=0.7)
plt.xlabel('Láº§n cháº¡y')
plt.ylabel('RÂ² Score')
plt.title('RANKING 10 Láº¦N CHáº Y', fontweight='bold')
plt.xticks(range(1, 11), [f'#{int(r)}' for r in ranking], rotation=45)

for i, (r2, rank) in enumerate(zip(test_df['r2'], ranking)):
    medal = 'ğŸ¥‡' if rank == 1 else 'ğŸ¥ˆ' if rank == 2 else 'ğŸ¥‰' if rank == 3 else ''
    plt.text(i+1, r2 + 0.002, f'{r2:.4f}\n{medal}', ha='center', va='bottom', 
             fontsize=8, fontweight='bold')

plt.tight_layout()
plt.savefig(detailed_runs_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {detailed_runs_path}")
# ============================
# BÆ¯á»šC 8: Váº¼ VÃ€ LÆ¯U CÃ‚Y QUYáº¾T Äá»ŠNH
# ============================
print(f"\nğŸŒ³ 7. Váº½ vÃ  lÆ°u cÃ¢y quyáº¿t Ä‘á»‹nh")

tree_path = os.path.join('img', 'decision_tree.png')
plt.figure(figsize=(25, 12))
plot_tree(
    best_model,
    feature_names=['AT', 'V', 'AP', 'RH'],
    filled=True,
    rounded=True,
    impurity=True,
    fontsize=8,
    max_depth=3
)
plt.title(f"CÃ‚Y QUYáº¾T Äá»ŠNH - MÃ” HÃŒNH Tá»T NHáº¤T (Láº§n {best_model_info['run_id'] + 1})", 
          fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig(tree_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"   âœ… ÄÃ£ lÆ°u: {tree_path}")

# ============================
# BÆ¯á»šC 9: LÆ¯U Káº¾T QUáº¢ VÃ€O FILE EXCEL
# ============================
print("\nğŸ“Š 8. LÆ°u káº¿t quáº£ vÃ o file Excel")

excel_path = os.path.join('result', 'results_summary.xlsx')

with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
    
    # Sheet 1: Tá»•ng quan káº¿t quáº£
    summary_data = {
        'Metric': ['RÂ² Trung bÃ¬nh', 'RMSE Trung bÃ¬nh', 'MAE Trung bÃ¬nh', 'MAPE Trung bÃ¬nh',
                  'RÂ² Tá»‘t nháº¥t', 'Äá»™ lá»‡ch chuáº©n RÂ²', 'Sá»‘ láº§n cháº¡y', 'MÃ´ hÃ¬nh tá»‘t nháº¥t',
                  'Cross-Val RÂ²', 'Cross-Val RMSE'],
        'GiÃ¡ trá»‹': [f"{test_df['r2'].mean():.4f}", f"{test_df['rmse'].mean():.4f}", 
                   f"{test_df['mae'].mean():.4f}", f"{test_df['mape'].mean():.2f}%",
                   f"{best_model_info['test_r2']:.4f}", f"{test_df['r2'].std():.4f}",
                   '10', f"Láº§n {best_model_info['run_id'] + 1}",
                   f"{cv_test_r2.mean():.4f}", f"{cv_test_rmse.mean():.4f}"],
        'ÄÃ¡nh giÃ¡': [f"{'âœ… Tá»‘t' if test_df['r2'].mean() > 0.9 else 'âš ï¸ KhÃ¡'}", 
                    f"{'âœ… Tá»‘t' if test_df['rmse'].mean() < 5 else 'âš ï¸ Trung bÃ¬nh'}",
                    f"{'âœ… Tá»‘t' if test_df['mae'].mean() < 4 else 'âš ï¸ Trung bÃ¬nh'}",
                    f"{'âœ… Tá»‘t' if test_df['mape'].mean() < 5 else 'âš ï¸ KhÃ¡'}",
                    'ğŸ† Tá»‘t nháº¥t', f"{'á»”n Ä‘á»‹nh' if test_df['r2'].std() < 0.02 else 'Biáº¿n Ä‘á»™ng'}",
                    'Äá»§', 'ÄÃ£ chá»n',
                    f"{'âœ… Tá»‘t' if cv_test_r2.mean() > 0.9 else 'âš ï¸ KhÃ¡'}",
                    f"{'âœ… Tá»‘t' if cv_test_rmse.mean() < 5 else 'âš ï¸ Trung bÃ¬nh'}"]
    }
    pd.DataFrame(summary_data).to_excel(writer, sheet_name='Tá»•ng quan', index=False)
    
    # Sheet 2: So sÃ¡nh mÃ´ hÃ¬nh
    model_comparison = {
        'MÃ´ hÃ¬nh': ['Decision Tree', 'Random Forest', 'KNN'],
        'RÂ²': [dt_metrics_best['r2'], rf_metrics['r2'], knn_metrics['r2']],
        'RMSE': [dt_metrics_best['rmse'], rf_metrics['rmse'], knn_metrics['rmse']],
        'MAE': [dt_metrics_best['mae'], rf_metrics['mae'], knn_metrics['mae']],
        'MAPE': [f"{dt_metrics_best['mape']:.2f}%", f"{rf_metrics['mape']:.2f}%", f"{knn_metrics['mape']:.2f}%"],
        'ÄÃ¡nh giÃ¡': [f"{'âœ… Tá»‘t' if dt_metrics_best['r2'] > 0.9 else 'âš ï¸ KhÃ¡'}",
                    f"{'âœ… Tá»‘t' if rf_metrics['r2'] > 0.9 else 'âš ï¸ KhÃ¡'}",
                    f"{'âœ… Tá»‘t' if knn_metrics['r2'] > 0.9 else 'âš ï¸ KhÃ¡'}"]
    }
    pd.DataFrame(model_comparison).to_excel(writer, sheet_name='So sÃ¡nh mÃ´ hÃ¬nh', index=False)
    
    # Sheet 3: Feature Importance
    feature_importance_df.to_excel(writer, sheet_name='Feature Importance', index=False)
    
    # Sheet 4: Káº¿t quáº£ 10 láº§n cháº¡y
    detailed_results = test_df.copy()
    detailed_results['Láº§n cháº¡y'] = range(1, 11)
    detailed_results.to_excel(writer, sheet_name='10 Láº§n cháº¡y', index=False)
    
    # Sheet 5: Tham sá»‘ mÃ´ hÃ¬nh tá»‘t nháº¥t
    best_params_df = pd.DataFrame([best_model_info['params']])
    best_params_df['Test_R2'] = best_model_info['test_r2']
    best_params_df['Láº§n_cháº¡y'] = best_model_info['run_id'] + 1
    best_params_df.to_excel(writer, sheet_name='MÃ´ hÃ¬nh tá»‘t nháº¥t', index=False)
    
    # Sheet 6: Cross-validation results
    cv_details = pd.DataFrame({
        'Fold': range(1, 6),
        'Train_R2': cv_train_r2,
        'Test_R2': cv_test_r2,
        'Test_RMSE': cv_test_rmse,
        'Test_MAE': cv_test_mae
    })
    cv_details.to_excel(writer, sheet_name='Cross-Validation', index=False)

print(f"âœ… ÄÃ£ lÆ°u file Excel tá»•ng há»£p: {excel_path}")

# ============================
# BÆ¯á»šC 10: Tá»”NG Káº¾T VÃ€ Káº¾T LUáº¬N
# ============================
print("\n" + "="*60)
print("ğŸ¯ Tá»”NG Káº¾T Káº¾T QUáº¢")
print("="*60)

# ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng tá»•ng thá»ƒ
avg_test_r2 = test_df['r2'].mean()
std_test_r2 = test_df['r2'].std()

if avg_test_r2 > 0.95 and std_test_r2 < 0.01:
    stability = "Ráº¤T á»”N Äá»ŠNH VÃ€ XUáº¤T Sáº®C ğŸ†"
elif avg_test_r2 > 0.9 and std_test_r2 < 0.02:
    stability = "á»”N Äá»ŠNH VÃ€ Tá»T âœ…"
elif avg_test_r2 > 0.85:
    stability = "KHÃ á»”N Äá»ŠNH ğŸ“Š"
else:
    stability = "Cáº¦N Cáº¢I THIá»†N âš ï¸"

print(f"\nğŸ“ˆ Káº¾T QUáº¢ Tá»”NG Há»¢P:")
print(f"   â€¢ Sá»‘ láº§n huáº¥n luyá»‡n: 10")
print(f"   â€¢ Sá»‘ bá»™ tham sá»‘ khÃ¡c nhau: 10")
print(f"   â€¢ MÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘áº¡t Test RÂ²: {best_model_info['test_r2']:.4f}")

print(f"\nğŸ“Š CHáº¤T LÆ¯á»¢NG TRUNG BÃŒNH (10 láº§n):")
print(f"   â€¢ RÂ² trung bÃ¬nh: {avg_test_r2:.4f} (Â±{std_test_r2:.4f})")
print(f"   â€¢ RMSE trung bÃ¬nh: {test_df['rmse'].mean():.4f} (Â±{test_df['rmse'].std():.4f})")
print(f"   â€¢ MAE trung bÃ¬nh: {test_df['mae'].mean():.4f} (Â±{test_df['mae'].std():.4f})")
print(f"   â€¢ Äá»™ á»•n Ä‘á»‹nh: {stability}")

print(f"\nğŸ” Äáº¶C TRÆ¯NG QUAN TRá»ŒNG NHáº¤T:")
best_feature = feature_importance_df.iloc[0]
print(f"   â€¢ {best_feature['Äáº·c trÆ°ng']}: {best_feature['Äá»™ quan trá»ng trung bÃ¬nh']:.4f} "
      f"(Â±{best_feature['Äá»™ lá»‡ch chuáº©n']:.4f})")

print(f"\nâš™ï¸ Bá»˜ THAM Sá» Tá»T NHáº¤T (Láº§n {best_model_info['run_id'] + 1}):")
for key, value in best_model_info['params'].items():
    print(f"   â€¢ {key}: {value if value is not None else 'KhÃ´ng giá»›i háº¡n'}")

print(f"\nğŸ“ Káº¾T QUáº¢ ÄÃƒ ÄÆ¯á»¢C LÆ¯U:")
print(f"   â€¢ ğŸ“Š áº¢nh biá»ƒu Ä‘á»“: {len(os.listdir('img'))} file trong thÆ° má»¥c 'img/'")
print(f"   â€¢ ğŸ’¾ Model & Data: {len(os.listdir('result'))} file trong thÆ° má»¥c 'result/'")
print(f"   â€¢ ğŸ“ˆ File Excel: result/results_summary.xlsx")
print(f"\nğŸ“ˆ BIá»‚U Äá»’ SO SÃNH 10 Láº¦N Láº¶P ÄÃƒ ÄÆ¯á»¢C Táº O:")
print(f"   â€¢ {comparison_10_runs_path}")
print(f"   â€¢ {detailed_runs_path}")
print(f"   â€¢ Tá»•ng cá»™ng: {len(os.listdir('img'))} file áº£nh trong thÆ° má»¥c 'img/'")
print(f"\nğŸ‰ HOÃ€N THÃ€NH PHÃ‚N TÃCH!")
print("="*60)